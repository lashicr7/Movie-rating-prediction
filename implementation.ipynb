{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief architecture:\n",
    "\n",
    "Data preprocessing ( pipeline ):\n",
    "Removing duplicates\n",
    "Removing some missing data\n",
    "Removing outliers ( z-score )\n",
    "Imputing missing data for relevant fields as runtime, theatre date\n",
    "Transforming the data as genre, rating (for relevant values)\n",
    "Adding new relevant columns as theatre year..\n",
    "Encoding categorical values (one - hot encoding, ordinal encoding)\n",
    "Scaling the data ( standard scaler , min-max scaler )\n",
    "Handling Imbalances ( SMOTE )\n",
    "Feature selection ( PCA, manual selection )\n",
    "\n",
    "Model:\n",
    "Regression model ( using random forest, xgboost, Feedforward NN(linear) )\n",
    "Classification model (Feedforward NN(soft max) )\n",
    "Semantic model ( sentence transformer: all-MiniLM-L6-v2,Feedforward NN &  xgboost )\n",
    "\n",
    "Metrics:\n",
    "MAE\n",
    "Tolerance accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please find doc link for explaination and inferences : https://docs.google.com/document/d/1PL6G-HlWOmCGfYIgOqRAm7a7u9vsV3H9lfXjHjSS5wk/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn==1.3.2) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn==1.3.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn==1.3.2) (3.2.0)\n",
      "Requirement already satisfied: imblearn in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.3.2\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./Rotten_Tomatoes_Movies3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_title', 'movie_info', 'critics_consensus', 'rating', 'genre',\n",
       "       'directors', 'writers', 'cast', 'in_theaters_date', 'on_streaming_date',\n",
       "       'runtime_in_minutes', 'studio_name', 'tomatometer_status',\n",
       "       'tomatometer_rating', 'tomatometer_count', 'audience_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_info</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "      <th>cast</th>\n",
       "      <th>in_theaters_date</th>\n",
       "      <th>on_streaming_date</th>\n",
       "      <th>runtime_in_minutes</th>\n",
       "      <th>studio_name</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>A teenager discovers he's the descendant of a ...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>Craig Titley</td>\n",
       "      <td>Logan Lerman, Brandon T. Jackson, Alexandra Da...</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>6/29/2010</td>\n",
       "      <td>83.0</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Give</td>\n",
       "      <td>Kate has a lot on her mind. There's the ethics...</td>\n",
       "      <td>Nicole Holofcener's newest might seem slight i...</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Catherine Keener, Amanda Peet, Oliver Platt, R...</td>\n",
       "      <td>4/30/2010</td>\n",
       "      <td>10/19/2010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sony Pictures Classics</td>\n",
       "      <td>Certified Fresh</td>\n",
       "      <td>86</td>\n",
       "      <td>140</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Blake Edwards' 10 stars Dudley Moore as George...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>Dudley Moore, Bo Derek, Julie Andrews, Robert ...</td>\n",
       "      <td>10/5/1979</td>\n",
       "      <td>8/27/1997</td>\n",
       "      <td>118.0</td>\n",
       "      <td>Waner Bros.</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>A Puerto Rican youth is on trial for murder, a...</td>\n",
       "      <td>Sidney Lumet's feature debut is a superbly wri...</td>\n",
       "      <td>NR</td>\n",
       "      <td>Classics, Drama</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Reginald Rose</td>\n",
       "      <td>Martin Balsam, John Fiedler, Lee J. Cobb, E.G....</td>\n",
       "      <td>4/13/1957</td>\n",
       "      <td>3/6/2001</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Criterion Collection</td>\n",
       "      <td>Certified Fresh</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>This 1954 Disney version of Jules Verne's 20,0...</td>\n",
       "      <td>One of Disney's finest live-action adventures,...</td>\n",
       "      <td>G</td>\n",
       "      <td>Action &amp; Adventure, Drama, Kids &amp; Family</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>Earl Felton</td>\n",
       "      <td>James Mason, Kirk Douglas, Paul Lukas, Peter L...</td>\n",
       "      <td>1/1/1954</td>\n",
       "      <td>5/20/2003</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1                                        Please Give   \n",
       "2                                                 10   \n",
       "3                    12 Angry Men (Twelve Angry Men)   \n",
       "4                       20,000 Leagues Under The Sea   \n",
       "\n",
       "                                          movie_info  \\\n",
       "0  A teenager discovers he's the descendant of a ...   \n",
       "1  Kate has a lot on her mind. There's the ethics...   \n",
       "2  Blake Edwards' 10 stars Dudley Moore as George...   \n",
       "3  A Puerto Rican youth is on trial for murder, a...   \n",
       "4  This 1954 Disney version of Jules Verne's 20,0...   \n",
       "\n",
       "                                   critics_consensus rating  \\\n",
       "0  Though it may seem like just another Harry Pot...     PG   \n",
       "1  Nicole Holofcener's newest might seem slight i...      R   \n",
       "2                                                NaN      R   \n",
       "3  Sidney Lumet's feature debut is a superbly wri...     NR   \n",
       "4  One of Disney's finest live-action adventures,...      G   \n",
       "\n",
       "                                               genre          directors  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
       "1                                             Comedy  Nicole Holofcener   \n",
       "2                                    Comedy, Romance      Blake Edwards   \n",
       "3                                    Classics, Drama       Sidney Lumet   \n",
       "4           Action & Adventure, Drama, Kids & Family  Richard Fleischer   \n",
       "\n",
       "             writers                                               cast  \\\n",
       "0       Craig Titley  Logan Lerman, Brandon T. Jackson, Alexandra Da...   \n",
       "1  Nicole Holofcener  Catherine Keener, Amanda Peet, Oliver Platt, R...   \n",
       "2      Blake Edwards  Dudley Moore, Bo Derek, Julie Andrews, Robert ...   \n",
       "3      Reginald Rose  Martin Balsam, John Fiedler, Lee J. Cobb, E.G....   \n",
       "4        Earl Felton  James Mason, Kirk Douglas, Paul Lukas, Peter L...   \n",
       "\n",
       "  in_theaters_date on_streaming_date  runtime_in_minutes  \\\n",
       "0        2/12/2010         6/29/2010                83.0   \n",
       "1        4/30/2010        10/19/2010                90.0   \n",
       "2        10/5/1979         8/27/1997               118.0   \n",
       "3        4/13/1957          3/6/2001                95.0   \n",
       "4         1/1/1954         5/20/2003               127.0   \n",
       "\n",
       "              studio_name tomatometer_status  tomatometer_rating  \\\n",
       "0        20th Century Fox             Rotten                  49   \n",
       "1  Sony Pictures Classics    Certified Fresh                  86   \n",
       "2             Waner Bros.              Fresh                  68   \n",
       "3    Criterion Collection    Certified Fresh                 100   \n",
       "4                  Disney              Fresh                  89   \n",
       "\n",
       "   tomatometer_count  audience_rating  \n",
       "0                144             53.0  \n",
       "1                140             64.0  \n",
       "2                 22             53.0  \n",
       "3                 51             97.0  \n",
       "4                 27             74.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = dataset['audience_rating'].dropna()\n",
    "is_discrete = all(cleaned_data % 1 == 0)\n",
    "print(is_discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code snippet confirms that rating is given as a discrete variable(classification) instead of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for Duplicates ---\n",
      "Number of Duplicate movies: 532\n",
      "Number of Duplicate Rows: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Checking for Duplicates ---\")\n",
    "duplicate_movies = dataset['movie_title'].duplicated().sum()\n",
    "duplicates = dataset.duplicated().sum()\n",
    "print(f\"Number of Duplicate movies: {duplicate_movies}\")\n",
    "print(f\"Number of Duplicate Rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = dataset[dataset.duplicated(keep=False)]\n",
    "# print(duplicate_rows)\n",
    "dataset = dataset.drop_duplicates(keep=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "combined_column = dataset[['movie_title', 'in_theaters_date']]\n",
    "duplicates_combined = combined_column.duplicated(keep=False).sum()\n",
    "print(duplicates_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are around 500 duplicates in respect to movie titles\n",
    "- But when it is combined with features as in_theatres_date they've drastically reduced to 4\n",
    "- which can be ignored , since for a movie can be re-released with same name later which is having different review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_title :\n",
      "Missing Values: 0 (0.00%)\n",
      "Number of Unique Values: 16105\n",
      "movie_info :\n",
      "Missing Values: 24 (0.14%)\n",
      "Number of Unique Values: 16612\n",
      "critics_consensus :\n",
      "Missing Values: 8327 (50.05%)\n",
      "Number of Unique Values: 8307\n",
      "rating :\n",
      "Missing Values: 0 (0.00%)\n",
      "Number of Unique Values: 8\n",
      "genre :\n",
      "Missing Values: 17 (0.10%)\n",
      "Number of Unique Values: 1080\n",
      "directors :\n",
      "Missing Values: 114 (0.69%)\n",
      "Number of Unique Values: 8314\n",
      "writers :\n",
      "Missing Values: 1349 (8.11%)\n",
      "Number of Unique Values: 12120\n",
      "cast :\n",
      "Missing Values: 284 (1.71%)\n",
      "Number of Unique Values: 16325\n",
      "in_theaters_date :\n",
      "Missing Values: 815 (4.90%)\n",
      "Number of Unique Values: 5585\n",
      "on_streaming_date :\n",
      "Missing Values: 2 (0.01%)\n",
      "Number of Unique Values: 2260\n",
      "runtime_in_minutes :\n",
      "Missing Values: 155 (0.93%)\n",
      "Number of Unique Values: 201\n",
      "studio_name :\n",
      "Missing Values: 414 (2.49%)\n",
      "Number of Unique Values: 2886\n",
      "tomatometer_status :\n",
      "Missing Values: 0 (0.00%)\n",
      "Number of Unique Values: 3\n",
      "tomatometer_rating :\n",
      "Missing Values: 0 (0.00%)\n",
      "Number of Unique Values: 101\n",
      "tomatometer_count :\n",
      "Missing Values: 0 (0.00%)\n",
      "Number of Unique Values: 393\n",
      "audience_rating :\n",
      "Missing Values: 252 (1.51%)\n",
      "Number of Unique Values: 98\n"
     ]
    }
   ],
   "source": [
    "for col in dataset.columns: \n",
    "        print(col,\":\")\n",
    "        # Missing values\n",
    "        missing_vals = dataset[col].isnull().sum()\n",
    "        missing_pct = (missing_vals / len(dataset)) * 100\n",
    "        print(f\"Missing Values: {missing_vals} ({missing_pct:.2f}%)\")\n",
    "        \n",
    "        # Number of unique values\n",
    "        unique_vals = dataset[col].nunique()\n",
    "        print(f\"Number of Unique Values: {unique_vals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference from above:\n",
    "- There are some data with missing audience rating (1.5%), can use them in test data but since the fraction is too low removing will ensure data sanity ( same for 'genre' column)\n",
    "- Missing data is very high (almost 50%) in critic consensus hence we'll remove that column for baseline model\n",
    "- We can impute the data accordingly for runtime, theatre dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=['genre']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=['audience_rating']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=['in_theaters_date', 'on_streaming_date'], how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2000.0\n",
      "17\n",
      "10\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "print(dataset['runtime_in_minutes'].min())\n",
    "print(dataset['runtime_in_minutes'].max())\n",
    "print(len(dataset[dataset['runtime_in_minutes']<20]))\n",
    "print(len(dataset[dataset['runtime_in_minutes']>250]))\n",
    "print(dataset['runtime_in_minutes'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset['runtime_in_minutes'][dataset['runtime_in_minutes'] < 250].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Runtime in Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Movie Runtime in Minutes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing data for runtime using the median which won't be effected by the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_median = dataset['runtime_in_minutes'].median()\n",
    "dataset['runtime_in_minutes'].fillna(runtime_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers using Z-Score method:\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "runtime_non_null = dataset['runtime_in_minutes']\n",
    "z_scores = zscore(runtime_non_null)\n",
    "outliers_z = runtime_non_null[abs(z_scores) > 3]\n",
    "print(\"Outliers using Z-Score method:\")\n",
    "print(len(outliers_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "177.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outlier_mask = abs(z_scores) > 3\n",
    "dataset = dataset[~outlier_mask].reset_index(drop=True)\n",
    "print(dataset['runtime_in_minutes'].min())\n",
    "print(dataset['runtime_in_minutes'].max())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataset['runtime_in_minutes'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Runtime in Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Movie Runtime in Minutes (Cleaned)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset after removing outliers, duplicates and missing data\n",
      "16215\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset after removing outliers, duplicates and missing data\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Action & Adventure, Comedy, Drama, Science Fic...\n",
       "1                                                Comedy\n",
       "2                                       Comedy, Romance\n",
       "3                                       Classics, Drama\n",
       "4              Action & Adventure, Drama, Kids & Family\n",
       "5                   Action & Adventure, Classics, Drama\n",
       "6      Action & Adventure, Classics, Mystery & Suspense\n",
       "7                              Classics, Drama, Western\n",
       "8                                Comedy, Drama, Romance\n",
       "9                                       Classics, Drama\n",
       "10    Art House & International, Horror, Mystery & S...\n",
       "Name: genre, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['genre'].loc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "{'classics', 'science fiction & fantasy', 'cult movies', 'romance', 'documentary', 'mystery & suspense', 'kids & family', 'musical & performing arts', 'television', 'comedy', 'art house & international', 'animation', 'action & adventure', 'faith & spirituality', 'gay & lesbian', 'anime & manga', 'western', 'special interest', 'sports & fitness', 'horror', 'drama'}\n"
     ]
    }
   ],
   "source": [
    "unique_genres = set()\n",
    "for i in range(len(dataset)):\n",
    "    genres = dataset['genre'].loc[i].split(\",\")\n",
    "    for j in genres:\n",
    "        unique_genres.add(j.strip().lower())\n",
    "\n",
    "print(len(unique_genres))\n",
    "print(unique_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the unique sub genres from the data, we'll use one-hot encoding for embedding the data for various genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = sorted(unique_genres)\n",
    "for genre in unique_genres:\n",
    "    dataset[genre] = dataset['genre'].apply(lambda x: 1 if genre in x.strip().lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG', 'R', 'NR', 'G', 'PG-13', 'PG-13)', 'NC17', 'R)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['rating'] = dataset['rating'].apply(lambda x: x[:-1] if x.endswith(')') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['in_theaters_date'] = pd.to_datetime(dataset['in_theaters_date'], errors='coerce')\n",
    "dataset['on_streaming_date'] = pd.to_datetime(dataset['on_streaming_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with theatre_date but no stream_date:\n",
      "0\n",
      "\n",
      "Movies with stream_date but no theatre_date:\n",
      "701\n",
      "\n",
      "Movies with neither theatre_date nor stream_date:\n",
      "0\n",
      "\n",
      "Average lag between theatre_date and stream_date (in days):\n",
      "3116.2306948562587\n"
     ]
    }
   ],
   "source": [
    "theatre_only = dataset[dataset['in_theaters_date'].notna() & dataset['on_streaming_date'].isna()]\n",
    "stream_only = dataset[dataset['on_streaming_date'].notna() & dataset['in_theaters_date'].isna()]\n",
    "neither = dataset[dataset['in_theaters_date'].isna() & dataset['on_streaming_date'].isna()]\n",
    "\n",
    "print(\"Movies with theatre_date but no stream_date:\")\n",
    "print(len(theatre_only['movie_title']))\n",
    "\n",
    "print(\"\\nMovies with stream_date but no theatre_date:\")\n",
    "print(len(stream_only['movie_title']))\n",
    "\n",
    "print(\"\\nMovies with neither theatre_date nor stream_date:\")\n",
    "print(len(neither['movie_title']))\n",
    "valid_lags = dataset\n",
    "average_lag = (valid_lags['on_streaming_date'] - valid_lags['in_theaters_date']).dt.days.mean()\n",
    "\n",
    "print(\"\\nAverage lag between theatre_date and stream_date (in days):\")\n",
    "print(average_lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above inference:\n",
    "- Average delay in theatre, stream is 3000 days ( approx 10 years ) due to old movies being released late\n",
    "- I initially thought of taking difference between theatre date, stream date which has correlation to movie's hype/ box office performance\n",
    "- Since the delay is too high, we can't take that for inferencing the audience rating (same is the case for movies directly streamed without theatrical release)\n",
    "- Also we can impute the missing theatre date with stream date - average lag (based on data)\n",
    "- But there might be a chance where the movie was directly shown on TV, hence we can't do the same\n",
    "- So for missing data, I've equated streaming date to theatre date\n",
    "- For capturing the trend of movies, I've taken year instead of day to maintain sparse relations ( avoiding overfitting )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['in_theaters_date'].isna() & dataset['on_streaming_date'].notna(), 'in_theaters_date'] = dataset['on_streaming_date']\n",
    "dataset['theatre_year'] = dataset['in_theaters_date'].dt.year\n",
    "dataset['stream_year'] = dataset['on_streaming_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_theaters_date</th>\n",
       "      <th>on_streaming_date</th>\n",
       "      <th>runtime_in_minutes</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>action &amp; adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>anime &amp; manga</th>\n",
       "      <th>art house &amp; international</th>\n",
       "      <th>...</th>\n",
       "      <th>musical &amp; performing arts</th>\n",
       "      <th>mystery &amp; suspense</th>\n",
       "      <th>romance</th>\n",
       "      <th>science fiction &amp; fantasy</th>\n",
       "      <th>special interest</th>\n",
       "      <th>sports &amp; fitness</th>\n",
       "      <th>television</th>\n",
       "      <th>western</th>\n",
       "      <th>theatre_year</th>\n",
       "      <th>stream_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16064</td>\n",
       "      <td>16064</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "      <td>16064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2000-05-24 16:14:34.900398336</td>\n",
       "      <td>2008-07-22 01:51:25.458167296</td>\n",
       "      <td>101.804096</td>\n",
       "      <td>60.167082</td>\n",
       "      <td>57.420443</td>\n",
       "      <td>60.315115</td>\n",
       "      <td>0.203312</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.144422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057395</td>\n",
       "      <td>0.203187</td>\n",
       "      <td>0.109562</td>\n",
       "      <td>0.105827</td>\n",
       "      <td>0.072896</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>1999.903386</td>\n",
       "      <td>2008.063496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1915-01-01 00:00:00</td>\n",
       "      <td>1935-06-06 00:00:00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1935.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1994-04-15 00:00:00</td>\n",
       "      <td>2003-01-21 00:00:00</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007-01-02 12:00:00</td>\n",
       "      <td>2008-03-18 00:00:00</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006.500000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013-10-04 00:00:00</td>\n",
       "      <td>2014-04-01 00:00:00</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019-10-25 00:00:00</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.204977</td>\n",
       "      <td>28.572880</td>\n",
       "      <td>66.660330</td>\n",
       "      <td>20.431489</td>\n",
       "      <td>0.402475</td>\n",
       "      <td>0.181207</td>\n",
       "      <td>0.030544</td>\n",
       "      <td>0.351528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232604</td>\n",
       "      <td>0.402383</td>\n",
       "      <td>0.312352</td>\n",
       "      <td>0.307625</td>\n",
       "      <td>0.259974</td>\n",
       "      <td>0.102330</td>\n",
       "      <td>0.120318</td>\n",
       "      <td>0.129719</td>\n",
       "      <td>19.153648</td>\n",
       "      <td>6.462209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    in_theaters_date              on_streaming_date  \\\n",
       "count                          16064                          16064   \n",
       "mean   2000-05-24 16:14:34.900398336  2008-07-22 01:51:25.458167296   \n",
       "min              1915-01-01 00:00:00            1935-06-06 00:00:00   \n",
       "25%              1994-04-15 00:00:00            2003-01-21 00:00:00   \n",
       "50%              2007-01-02 12:00:00            2008-03-18 00:00:00   \n",
       "75%              2013-10-04 00:00:00            2014-04-01 00:00:00   \n",
       "max              2019-10-25 00:00:00            2019-11-01 00:00:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "       runtime_in_minutes  tomatometer_rating  tomatometer_count  \\\n",
       "count        16064.000000        16064.000000       16064.000000   \n",
       "mean           101.804096           60.167082          57.420443   \n",
       "min             30.000000            0.000000           5.000000   \n",
       "25%             90.000000           38.000000          12.000000   \n",
       "50%             99.000000           65.000000          29.000000   \n",
       "75%            110.000000           85.000000          78.000000   \n",
       "max            177.000000          100.000000         497.000000   \n",
       "std             17.204977           28.572880          66.660330   \n",
       "\n",
       "       audience_rating  action & adventure     animation  anime & manga  \\\n",
       "count     16064.000000        16064.000000  16064.000000   16064.000000   \n",
       "mean         60.315115            0.203312      0.033989       0.000934   \n",
       "min           0.000000            0.000000      0.000000       0.000000   \n",
       "25%          44.000000            0.000000      0.000000       0.000000   \n",
       "50%          62.000000            0.000000      0.000000       0.000000   \n",
       "75%          77.000000            0.000000      0.000000       0.000000   \n",
       "max         100.000000            1.000000      1.000000       1.000000   \n",
       "std          20.431489            0.402475      0.181207       0.030544   \n",
       "\n",
       "       art house & international  ...  musical & performing arts  \\\n",
       "count               16064.000000  ...               16064.000000   \n",
       "mean                    0.144422  ...                   0.057395   \n",
       "min                     0.000000  ...                   0.000000   \n",
       "25%                     0.000000  ...                   0.000000   \n",
       "50%                     0.000000  ...                   0.000000   \n",
       "75%                     0.000000  ...                   0.000000   \n",
       "max                     1.000000  ...                   1.000000   \n",
       "std                     0.351528  ...                   0.232604   \n",
       "\n",
       "       mystery & suspense       romance  science fiction & fantasy  \\\n",
       "count        16064.000000  16064.000000               16064.000000   \n",
       "mean             0.203187      0.109562                   0.105827   \n",
       "min              0.000000      0.000000                   0.000000   \n",
       "25%              0.000000      0.000000                   0.000000   \n",
       "50%              0.000000      0.000000                   0.000000   \n",
       "75%              0.000000      0.000000                   0.000000   \n",
       "max              1.000000      1.000000                   1.000000   \n",
       "std              0.402383      0.312352                   0.307625   \n",
       "\n",
       "       special interest  sports & fitness    television       western  \\\n",
       "count      16064.000000      16064.000000  16064.000000  16064.000000   \n",
       "mean           0.072896          0.010583      0.014691      0.017119   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000      0.000000      0.000000   \n",
       "50%            0.000000          0.000000      0.000000      0.000000   \n",
       "75%            0.000000          0.000000      0.000000      0.000000   \n",
       "max            1.000000          1.000000      1.000000      1.000000   \n",
       "std            0.259974          0.102330      0.120318      0.129719   \n",
       "\n",
       "       theatre_year   stream_year  \n",
       "count  16064.000000  16064.000000  \n",
       "mean    1999.903386   2008.063496  \n",
       "min     1915.000000   1935.000000  \n",
       "25%     1994.000000   2003.000000  \n",
       "50%     2006.500000   2008.000000  \n",
       "75%     2013.000000   2014.000000  \n",
       "max     2019.000000   2019.000000  \n",
       "std       19.153648      6.462209  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=dataset['tomatometer_count'])\n",
    "plt.title(\"Boxplot for Tomatometer Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 302\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "tomatometer_count = dataset['tomatometer_count']\n",
    "z_scores = zscore(tomatometer_count)\n",
    "outliers_t = tomatometer_count[abs(z_scores) > 3]\n",
    "print(f\"Number of outliers: {len(outliers_t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check the removal of outliers in tomatometer_count based on results -- tree(robust to outliers) vs distance based techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Rotten', 'Certified Fresh', 'Fresh']])\n",
    "dataset['status'] = ordinal_encoder.fit_transform(dataset[['tomatometer_status']])\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['PG', 'R', 'NR', 'G', 'PG-13', 'NC17']]) \n",
    "dataset['rating_encoded'] = ordinal_encoder.fit_transform(dataset[['rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "dataset['runtime_in_minutes_scaled'] = standard_scaler.fit_transform(dataset[['runtime_in_minutes']])\n",
    "dataset[['tomatometer_count_scaled', 'theatre_year_scaled', 'stream_year_scaled', 'tomatometer_rating_scaled']] = min_max_scaler.fit_transform(dataset[['tomatometer_count', 'theatre_year', 'stream_year','tomatometer_rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['movie_title', 'movie_info', 'critics_consensus', 'directors', \n",
    "                   'writers', 'cast', 'in_theaters_date', 'on_streaming_date', 'studio_name', 'genre', 'tomatometer_status', 'rating', 'runtime_in_minutes', 'tomatometer_count','theatre_year', 'stream_year','tomatometer_rating']\n",
    "dataset = dataset.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['audience_rating', 'action & adventure', 'animation', 'anime & manga',\n",
       "       'art house & international', 'classics', 'comedy', 'cult movies',\n",
       "       'documentary', 'drama', 'faith & spirituality', 'gay & lesbian',\n",
       "       'horror', 'kids & family', 'musical & performing arts',\n",
       "       'mystery & suspense', 'romance', 'science fiction & fantasy',\n",
       "       'special interest', 'sports & fitness', 'television', 'western',\n",
       "       'status', 'rating_encoded', 'runtime_in_minutes_scaled',\n",
       "       'tomatometer_count_scaled', 'theatre_year_scaled', 'stream_year_scaled',\n",
       "       'tomatometer_rating_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling data imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audience_rating\n",
      "0.0       5\n",
      "4.0       2\n",
      "5.0       5\n",
      "6.0       2\n",
      "7.0       4\n",
      "         ..\n",
      "96.0     28\n",
      "97.0     16\n",
      "98.0      6\n",
      "99.0      3\n",
      "100.0    25\n",
      "Name: count, Length: 98, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check class counts\n",
    "class_counts = dataset['audience_rating'].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.index, class_counts.values, color='skyblue')\n",
    "plt.title(\"Class Distribution of Audience Ratings (0-100)\")\n",
    "plt.xlabel(\"Audience Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "audience_rating\n",
      "72.0    320\n",
      "75.0    310\n",
      "78.0    292\n",
      "76.0    286\n",
      "77.0    285\n",
      "       ... \n",
      "8.0       5\n",
      "7.0       4\n",
      "99.0      3\n",
      "4.0       2\n",
      "6.0       2\n",
      "Name: count, Length: 98, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X = dataset.drop(columns=['audience_rating'])\n",
    "y = dataset['audience_rating']\n",
    "class_counts = y.value_counts()\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(class_counts)\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)  # Since for some classes there're too low samples\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (sorted):\n",
      "anime & manga: 0.0000\n",
      "cult movies: 0.0001\n",
      "gay & lesbian: 0.0001\n",
      "faith & spirituality: 0.0002\n",
      "sports & fitness: 0.0002\n",
      "western: 0.0004\n",
      "classics: 0.0006\n",
      "animation: 0.0009\n",
      "musical & performing arts: 0.0013\n",
      "special interest: 0.0016\n",
      "science fiction & fantasy: 0.0020\n",
      "romance: 0.0027\n",
      "kids & family: 0.0035\n",
      "art house & international: 0.0047\n",
      "action & adventure: 0.0068\n",
      "horror: 0.0104\n",
      "television: 0.0120\n",
      "mystery & suspense: 0.0136\n",
      "comedy: 0.0521\n",
      "drama: 0.0695\n",
      "documentary: 0.0721\n",
      "theatre_year_scaled: 0.0997\n",
      "rating_encoded: 0.1082\n",
      "stream_year_scaled: 0.1616\n",
      "tomatometer_count_scaled: 0.1893\n",
      "status: 0.1974\n",
      "runtime_in_minutes_scaled: 0.2712\n",
      "tomatometer_rating: 0.9340\n",
      "Selected Features (Importance > 0.005): ['action & adventure', 'horror', 'television', 'mystery & suspense', 'comedy', 'drama', 'documentary', 'theatre_year_scaled', 'rating_encoded', 'stream_year_scaled', 'tomatometer_count_scaled', 'status', 'runtime_in_minutes_scaled', 'tomatometer_rating']\n",
      "Variance Inflation Factor (VIF):\n",
      "                      feature         VIF\n",
      "0          tomatometer_rating   13.383084\n",
      "1          action & adventure    1.345828\n",
      "2                   animation    1.376586\n",
      "3               anime & manga    1.030464\n",
      "4   art house & international    1.212780\n",
      "5                    classics    2.029725\n",
      "6                      comedy    1.513914\n",
      "7                 cult movies    1.016417\n",
      "8                 documentary    2.156440\n",
      "9                       drama    2.293004\n",
      "10       faith & spirituality    1.012387\n",
      "11              gay & lesbian    1.007252\n",
      "12                     horror    1.305077\n",
      "13              kids & family    1.389567\n",
      "14  musical & performing arts    1.111598\n",
      "15         mystery & suspense    1.304537\n",
      "16                    romance    1.170503\n",
      "17  science fiction & fantasy    1.208446\n",
      "18           special interest    1.576012\n",
      "19           sports & fitness    1.030722\n",
      "20                 television    1.034380\n",
      "21                    western    1.058432\n",
      "22                     status    5.212750\n",
      "23             rating_encoded    3.490908\n",
      "24  runtime_in_minutes_scaled    1.388078\n",
      "25   tomatometer_count_scaled    2.266659\n",
      "26        theatre_year_scaled   90.189895\n",
      "27         stream_year_scaled  107.467263\n",
      "Features to Drop due to High VIF: ['tomatometer_rating', 'theatre_year_scaled', 'stream_year_scaled']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "model_rf.fit(X_resampled, y_resampled)\n",
    "perm_importance = permutation_importance(\n",
    "    model_rf, X_resampled, y_resampled, n_repeats=10, random_state=42, scoring='r2'\n",
    ")\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "print(\"Feature Importance (sorted):\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{X_resampled.columns[i]}: {perm_importance.importances_mean[i]:.4f}\")\n",
    "important_features = [\n",
    "    X_resampled.columns[i]\n",
    "    for i in sorted_idx\n",
    "    if perm_importance.importances_mean[i] > 0.005\n",
    "]\n",
    "print(f\"Selected Features (Importance > 0.005): {important_features}\")\n",
    "\n",
    "\n",
    "#checking inter-feature dependence (multi collinearity)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_resampled.columns\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_resampled.values, i)\n",
    "    for i in range(X_resampled.shape[1])\n",
    "]\n",
    "\n",
    "print(\"Variance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n",
    "\n",
    "columns_to_drop_vif = vif_data[vif_data[\"VIF\"] > 10][\"feature\"].tolist()\n",
    "print(f\"Features to Drop due to High VIF: {columns_to_drop_vif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on aboove results, manually dropping some of the features which have low relevance and redundant from other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'western',\n",
    "    'faith & spirituality',\n",
    "    'anime & manga',\n",
    "    'gay & lesbian',\n",
    "    'cult movies',\n",
    "    'sports & fitness',\n",
    "    'stream_year_scaled',\n",
    "    'classics',\n",
    "    'animation',\n",
    "\n",
    "]\n",
    "X_resampled_final_manual_drop = X_resampled.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA for selecting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_resampled_final = pca.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled_final, y_resampled, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_manual, X_test_manual, y_train_manual, y_test_manual = train_test_split(\n",
    "    X_resampled_final_manual_drop, y_resampled, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model using PCA for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.265685586734694\n",
      "Rounded Accuracy: 0.15003188775510204\n",
      "Tolerance Accuracy (3): 35.30%\n",
      "Tolerance Accuracy (5): 47.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae}\")\n",
    "y_pred_rounded = np.round(y_pred)\n",
    "rounded_accuracy = (y_pred_rounded == y_test).mean()\n",
    "print(f\"Rounded Accuracy: {rounded_accuracy}\")\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest using manual feature selection through VIF, perm importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 7.974329931972789\n",
      "Rounded Accuracy: 0.14301658163265307\n",
      "Tolerance Accuracy (3): 35.76%\n",
      "Tolerance Accuracy (5): 48.37%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_manual, y_train_manual)\n",
    "y_pred = model.predict(X_test_manual)\n",
    "mae = mean_absolute_error(y_test_manual, y_pred)\n",
    "print(f\"MAE: {mae}\")\n",
    "\n",
    "y_pred_rounded = np.round(y_pred)\n",
    "rounded_accuracy = (y_pred_rounded == y_test_manual).mean()\n",
    "print(f\"Rounded Accuracy: {rounded_accuracy}\")\n",
    "\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test_manual) <= 3).sum() / len(y_test_manual)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test_manual) <= 5).sum() / len(y_test_manual)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "MAE: 8.920864141011036\n",
      "MSE: 158.1536359146956\n",
      "R Score: 0.8015766109214808\n",
      "Rounded Accuracy: 0.06712372448979592\n",
      "Tolerance Accuracy (3): 30.74%\n",
      "Tolerance Accuracy (5): 44.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R Score: {r2}\")\n",
    "\n",
    "y_pred_rounded = np.round(y_pred)\n",
    "rounded_accuracy = (y_pred_rounded == y_test).mean()\n",
    "print(f\"Rounded Accuracy: {rounded_accuracy}\")\n",
    "\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tolerance Accuracy (5): 44.01%\n",
      "Tolerance Accuracy (7): 53.62%\n"
     ]
    }
   ],
   "source": [
    "tolerance_10_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "tolerance_15_accuracy = ((np.abs(y_pred - y_test) <= 7).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_10_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (7): {tolerance_15_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_manual\n",
    "X_test = X_test_manual\n",
    "y_test = y_test_manual\n",
    "y_train = y_train_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lashicr7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                        \u001b[38;5;34m320\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                         \u001b[38;5;34m64\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                         \u001b[38;5;34m136\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m9\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529</span> (2.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m529\u001b[0m (2.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">497</span> (1.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m497\u001b[0m (1.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 2712.1270 - mae: 44.6877 - val_loss: 393.4956 - val_mae: 15.8651\n",
      "Epoch 2/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 379.1059 - mae: 15.3905 - val_loss: 282.4833 - val_mae: 12.8517\n",
      "Epoch 3/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 273.6189 - mae: 12.8234 - val_loss: 265.2467 - val_mae: 12.3597\n",
      "Epoch 4/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 275.3049 - mae: 12.8654 - val_loss: 259.3189 - val_mae: 12.0748\n",
      "Epoch 5/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 263.6676 - mae: 12.5186 - val_loss: 254.2563 - val_mae: 12.1482\n",
      "Epoch 6/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 253.2450 - mae: 12.3689 - val_loss: 252.0188 - val_mae: 12.0386\n",
      "Epoch 7/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 257.7725 - mae: 12.4144 - val_loss: 254.4786 - val_mae: 11.8864\n",
      "Epoch 8/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 252.9799 - mae: 12.3087 - val_loss: 250.1924 - val_mae: 11.9998\n",
      "Epoch 9/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 256.3854 - mae: 12.3431 - val_loss: 249.0622 - val_mae: 11.8011\n",
      "Epoch 10/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 257.5266 - mae: 12.3407 - val_loss: 247.8448 - val_mae: 11.9664\n",
      "Epoch 11/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 255.5497 - mae: 12.3159 - val_loss: 245.9929 - val_mae: 11.6758\n",
      "Epoch 12/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 249.4640 - mae: 12.1536 - val_loss: 244.2209 - val_mae: 11.7882\n",
      "Epoch 13/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 248.4130 - mae: 12.1163 - val_loss: 242.9507 - val_mae: 11.7836\n",
      "Epoch 14/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 249.5485 - mae: 12.1703 - val_loss: 243.1803 - val_mae: 11.8331\n",
      "Epoch 15/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 253.9557 - mae: 12.3334 - val_loss: 244.2826 - val_mae: 11.6440\n",
      "Epoch 16/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 251.7315 - mae: 12.2125 - val_loss: 242.1725 - val_mae: 11.7802\n",
      "Epoch 17/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 250.3942 - mae: 12.2555 - val_loss: 242.1891 - val_mae: 11.7695\n",
      "Epoch 18/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 247.0334 - mae: 12.1227 - val_loss: 252.4967 - val_mae: 11.9730\n",
      "Epoch 19/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 242.9686 - mae: 12.0392 - val_loss: 244.6740 - val_mae: 11.8229\n",
      "Epoch 20/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 243.3160 - mae: 12.0728 - val_loss: 242.9297 - val_mae: 11.8123\n",
      "Epoch 21/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 245.0477 - mae: 12.0777 - val_loss: 242.2535 - val_mae: 11.9550\n",
      "Epoch 22/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 246.5918 - mae: 12.0887 - val_loss: 239.4004 - val_mae: 11.7127\n",
      "Epoch 23/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 241.8234 - mae: 12.0065 - val_loss: 239.2393 - val_mae: 11.7848\n",
      "Epoch 24/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 241.2379 - mae: 12.0377 - val_loss: 241.2244 - val_mae: 11.8048\n",
      "Epoch 25/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 243.2666 - mae: 12.0501 - val_loss: 239.0608 - val_mae: 11.7550\n",
      "Epoch 26/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 239.9180 - mae: 11.9348 - val_loss: 241.2398 - val_mae: 11.9070\n",
      "Epoch 27/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 243.6212 - mae: 12.0658 - val_loss: 237.4736 - val_mae: 11.5996\n",
      "Epoch 28/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 242.7164 - mae: 11.9620 - val_loss: 241.7389 - val_mae: 11.5655\n",
      "Epoch 29/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 241.5505 - mae: 11.9193 - val_loss: 238.2431 - val_mae: 11.6432\n",
      "Epoch 30/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 246.4709 - mae: 12.0104 - val_loss: 237.3761 - val_mae: 11.5858\n",
      "Epoch 31/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 247.3279 - mae: 12.0626 - val_loss: 239.8252 - val_mae: 11.7296\n",
      "Epoch 32/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 243.0988 - mae: 11.9669 - val_loss: 238.0457 - val_mae: 11.6251\n",
      "Epoch 33/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.7324 - mae: 11.7904 - val_loss: 241.0630 - val_mae: 11.8030\n",
      "Epoch 34/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 242.5386 - mae: 12.0914 - val_loss: 236.2068 - val_mae: 11.5575\n",
      "Epoch 35/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 243.5069 - mae: 11.9715 - val_loss: 238.3795 - val_mae: 11.6193\n",
      "Epoch 36/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 237.7112 - mae: 11.8977 - val_loss: 235.6655 - val_mae: 11.5567\n",
      "Epoch 37/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 238.9808 - mae: 11.9178 - val_loss: 248.4487 - val_mae: 11.8475\n",
      "Epoch 38/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 236.7015 - mae: 11.8246 - val_loss: 243.5959 - val_mae: 11.8267\n",
      "Epoch 39/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 243.5828 - mae: 12.0071 - val_loss: 235.8684 - val_mae: 11.6787\n",
      "Epoch 40/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 240.9087 - mae: 12.0152 - val_loss: 236.2875 - val_mae: 11.5750\n",
      "Epoch 41/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 242.1766 - mae: 12.0088 - val_loss: 238.8945 - val_mae: 11.6514\n",
      "Epoch 42/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.6684 - mae: 11.8647 - val_loss: 236.9785 - val_mae: 11.6060\n",
      "Epoch 43/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 235.3712 - mae: 11.8476 - val_loss: 235.4501 - val_mae: 11.6332\n",
      "Epoch 44/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 241.8443 - mae: 12.0139 - val_loss: 235.9533 - val_mae: 11.5843\n",
      "Epoch 45/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 237.2409 - mae: 11.8172 - val_loss: 236.9670 - val_mae: 11.6627\n",
      "Epoch 46/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 238.7527 - mae: 11.8752 - val_loss: 235.3170 - val_mae: 11.5796\n",
      "Epoch 47/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.2047 - mae: 11.8903 - val_loss: 235.8719 - val_mae: 11.6159\n",
      "Epoch 48/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 228.6560 - mae: 11.6328 - val_loss: 235.6129 - val_mae: 11.6393\n",
      "Epoch 49/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 242.2517 - mae: 11.9569 - val_loss: 236.9246 - val_mae: 11.5839\n",
      "Epoch 50/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.6234 - mae: 11.7627 - val_loss: 237.8735 - val_mae: 11.6513\n",
      "Epoch 51/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 240.2051 - mae: 11.8826 - val_loss: 236.5890 - val_mae: 11.5831\n",
      "Epoch 52/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 234.3906 - mae: 11.7529 - val_loss: 236.0279 - val_mae: 11.6672\n",
      "Epoch 53/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 239.3975 - mae: 11.8994 - val_loss: 236.3996 - val_mae: 11.5619\n",
      "Epoch 54/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 237.5788 - mae: 11.8268 - val_loss: 236.3025 - val_mae: 11.6363\n",
      "Epoch 55/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 235.9205 - mae: 11.7893 - val_loss: 239.3758 - val_mae: 11.6746\n",
      "Epoch 56/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.4146 - mae: 11.7253 - val_loss: 236.4522 - val_mae: 11.6985\n",
      "Epoch 57/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 235.8585 - mae: 11.8271 - val_loss: 234.9481 - val_mae: 11.5386\n",
      "Epoch 58/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 235.2570 - mae: 11.7483 - val_loss: 233.7463 - val_mae: 11.5459\n",
      "Epoch 59/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 236.8438 - mae: 11.8355 - val_loss: 235.5831 - val_mae: 11.5366\n",
      "Epoch 60/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 235.4857 - mae: 11.7877 - val_loss: 234.1513 - val_mae: 11.6259\n",
      "Epoch 61/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.5971 - mae: 11.8840 - val_loss: 236.2427 - val_mae: 11.5267\n",
      "Epoch 62/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 239.0057 - mae: 11.8281 - val_loss: 234.7687 - val_mae: 11.5865\n",
      "Epoch 63/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 237.6959 - mae: 11.8619 - val_loss: 233.4595 - val_mae: 11.4924\n",
      "Epoch 64/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 231.2126 - mae: 11.6644 - val_loss: 233.9574 - val_mae: 11.5655\n",
      "Epoch 65/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.1168 - mae: 11.7151 - val_loss: 232.5786 - val_mae: 11.5466\n",
      "Epoch 66/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.4091 - mae: 11.6934 - val_loss: 235.1197 - val_mae: 11.6239\n",
      "Epoch 67/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 232.3162 - mae: 11.7281 - val_loss: 237.8912 - val_mae: 11.6407\n",
      "Epoch 68/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 230.5134 - mae: 11.6951 - val_loss: 232.8220 - val_mae: 11.5583\n",
      "Epoch 69/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 237.7539 - mae: 11.8242 - val_loss: 234.6052 - val_mae: 11.5823\n",
      "Epoch 70/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 235.3791 - mae: 11.8046 - val_loss: 243.3366 - val_mae: 11.9436\n",
      "Epoch 71/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 228.4266 - mae: 11.6763 - val_loss: 233.6063 - val_mae: 11.5508\n",
      "Epoch 72/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 230.6652 - mae: 11.7562 - val_loss: 231.5405 - val_mae: 11.5732\n",
      "Epoch 73/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.3704 - mae: 11.8066 - val_loss: 233.6884 - val_mae: 11.6556\n",
      "Epoch 74/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.2055 - mae: 11.8211 - val_loss: 233.1812 - val_mae: 11.5996\n",
      "Epoch 75/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.6665 - mae: 11.7618 - val_loss: 232.7200 - val_mae: 11.4694\n",
      "Epoch 76/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.7867 - mae: 11.6995 - val_loss: 234.6099 - val_mae: 11.6873\n",
      "Epoch 77/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.7882 - mae: 11.7158 - val_loss: 232.2925 - val_mae: 11.4926\n",
      "Epoch 78/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.3334 - mae: 11.7491 - val_loss: 235.3151 - val_mae: 11.6680\n",
      "Epoch 79/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.4904 - mae: 11.5868 - val_loss: 232.1398 - val_mae: 11.5817\n",
      "Epoch 80/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 231.5553 - mae: 11.7333 - val_loss: 231.3493 - val_mae: 11.5348\n",
      "Epoch 81/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.9626 - mae: 11.5788 - val_loss: 230.3419 - val_mae: 11.4842\n",
      "Epoch 82/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 238.1828 - mae: 11.8541 - val_loss: 231.5005 - val_mae: 11.4905\n",
      "Epoch 83/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 229.9199 - mae: 11.6668 - val_loss: 232.0576 - val_mae: 11.5411\n",
      "Epoch 84/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 234.6115 - mae: 11.7537 - val_loss: 231.4119 - val_mae: 11.5248\n",
      "Epoch 85/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.9512 - mae: 11.7727 - val_loss: 232.5217 - val_mae: 11.5531\n",
      "Epoch 86/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.4994 - mae: 11.7389 - val_loss: 230.7259 - val_mae: 11.4922\n",
      "Epoch 87/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.4483 - mae: 11.6790 - val_loss: 230.9757 - val_mae: 11.5532\n",
      "Epoch 88/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.5373 - mae: 11.7116 - val_loss: 229.7514 - val_mae: 11.3900\n",
      "Epoch 89/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 238.1265 - mae: 11.8597 - val_loss: 229.4024 - val_mae: 11.4639\n",
      "Epoch 90/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.2751 - mae: 11.7268 - val_loss: 229.7344 - val_mae: 11.4507\n",
      "Epoch 91/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.0736 - mae: 11.5752 - val_loss: 239.4863 - val_mae: 11.7928\n",
      "Epoch 92/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 231.9601 - mae: 11.6983 - val_loss: 230.2521 - val_mae: 11.5046\n",
      "Epoch 93/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.0681 - mae: 11.6987 - val_loss: 234.5796 - val_mae: 11.5785\n",
      "Epoch 94/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.0630 - mae: 11.6422 - val_loss: 229.3650 - val_mae: 11.4199\n",
      "Epoch 95/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.7829 - mae: 11.6468 - val_loss: 229.0332 - val_mae: 11.4355\n",
      "Epoch 96/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.2110 - mae: 11.6492 - val_loss: 228.7305 - val_mae: 11.4671\n",
      "Epoch 97/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 228.9924 - mae: 11.6697 - val_loss: 230.7478 - val_mae: 11.4422\n",
      "Epoch 98/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 228.2408 - mae: 11.6215 - val_loss: 230.8912 - val_mae: 11.5247\n",
      "Epoch 99/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 229.1133 - mae: 11.6467 - val_loss: 230.3648 - val_mae: 11.5248\n",
      "Epoch 100/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.0339 - mae: 11.7720 - val_loss: 227.6347 - val_mae: 11.4218\n",
      "Epoch 101/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 230.5811 - mae: 11.6946 - val_loss: 227.3992 - val_mae: 11.3796\n",
      "Epoch 102/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 235.2876 - mae: 11.8127 - val_loss: 231.6182 - val_mae: 11.5502\n",
      "Epoch 103/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.5894 - mae: 11.7434 - val_loss: 229.9134 - val_mae: 11.5325\n",
      "Epoch 104/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.3832 - mae: 11.7288 - val_loss: 227.5552 - val_mae: 11.3724\n",
      "Epoch 105/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.1500 - mae: 11.6141 - val_loss: 227.1892 - val_mae: 11.4469\n",
      "Epoch 106/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 231.9300 - mae: 11.7104 - val_loss: 233.1891 - val_mae: 11.5298\n",
      "Epoch 107/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 229.2231 - mae: 11.6382 - val_loss: 228.1871 - val_mae: 11.4602\n",
      "Epoch 108/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 235.1894 - mae: 11.7933 - val_loss: 231.0583 - val_mae: 11.4920\n",
      "Epoch 109/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 231.4745 - mae: 11.7477 - val_loss: 228.1927 - val_mae: 11.3735\n",
      "Epoch 110/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 225.7174 - mae: 11.5335 - val_loss: 236.0324 - val_mae: 11.7033\n",
      "Epoch 111/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.2572 - mae: 11.6960 - val_loss: 231.7662 - val_mae: 11.4961\n",
      "Epoch 112/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.7421 - mae: 11.6850 - val_loss: 231.0827 - val_mae: 11.4819\n",
      "Epoch 113/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 234.4464 - mae: 11.7718 - val_loss: 228.9251 - val_mae: 11.5352\n",
      "Epoch 114/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 229.9311 - mae: 11.6058 - val_loss: 227.0597 - val_mae: 11.3906\n",
      "Epoch 115/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 225.8943 - mae: 11.5978 - val_loss: 225.7972 - val_mae: 11.3099\n",
      "Epoch 116/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 227.2746 - mae: 11.5655 - val_loss: 226.4588 - val_mae: 11.3141\n",
      "Epoch 117/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 230.4637 - mae: 11.6801 - val_loss: 226.3981 - val_mae: 11.3637\n",
      "Epoch 118/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.8957 - mae: 11.5870 - val_loss: 228.7218 - val_mae: 11.4651\n",
      "Epoch 119/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 229.7942 - mae: 11.6641 - val_loss: 230.1790 - val_mae: 11.4887\n",
      "Epoch 120/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 229.8743 - mae: 11.6693 - val_loss: 227.6052 - val_mae: 11.3775\n",
      "Epoch 121/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 225.6335 - mae: 11.5306 - val_loss: 228.2174 - val_mae: 11.4280\n",
      "Epoch 122/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 228.9721 - mae: 11.6249 - val_loss: 225.7365 - val_mae: 11.3521\n",
      "Epoch 123/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 234.2683 - mae: 11.7815 - val_loss: 232.2474 - val_mae: 11.4124\n",
      "Epoch 124/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.8859 - mae: 11.7125 - val_loss: 229.8631 - val_mae: 11.4353\n",
      "Epoch 125/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.0210 - mae: 11.6322 - val_loss: 230.7020 - val_mae: 11.4941\n",
      "Epoch 126/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 228.8544 - mae: 11.6380 - val_loss: 228.2067 - val_mae: 11.4106\n",
      "Epoch 127/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 230.1973 - mae: 11.6499 - val_loss: 227.4560 - val_mae: 11.3693\n",
      "Epoch 128/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 228.3706 - mae: 11.6293 - val_loss: 228.1276 - val_mae: 11.4710\n",
      "Epoch 129/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 234.9848 - mae: 11.7278 - val_loss: 228.4079 - val_mae: 11.4091\n",
      "Epoch 130/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 228.8669 - mae: 11.5845 - val_loss: 227.9549 - val_mae: 11.4637\n",
      "Epoch 131/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.5887 - mae: 11.6472 - val_loss: 226.7107 - val_mae: 11.3821\n",
      "Epoch 132/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.5334 - mae: 11.5442 - val_loss: 226.8630 - val_mae: 11.3623\n",
      "Epoch 133/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.0666 - mae: 11.5647 - val_loss: 225.6233 - val_mae: 11.3414\n",
      "Epoch 134/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 227.8849 - mae: 11.5880 - val_loss: 227.0851 - val_mae: 11.4435\n",
      "Epoch 135/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 234.4356 - mae: 11.7250 - val_loss: 226.2714 - val_mae: 11.4163\n",
      "Epoch 136/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.3157 - mae: 11.6813 - val_loss: 227.1673 - val_mae: 11.4715\n",
      "Epoch 137/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 225.4601 - mae: 11.4890 - val_loss: 228.0279 - val_mae: 11.3027\n",
      "Epoch 138/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 226.0229 - mae: 11.5635 - val_loss: 228.0155 - val_mae: 11.3324\n",
      "Epoch 139/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 224.0653 - mae: 11.4951 - val_loss: 228.4711 - val_mae: 11.4534\n",
      "Epoch 140/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.2312 - mae: 11.6795 - val_loss: 225.8975 - val_mae: 11.3604\n",
      "Epoch 141/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 227.9259 - mae: 11.5592 - val_loss: 225.9028 - val_mae: 11.4053\n",
      "Epoch 142/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 229.7236 - mae: 11.6406 - val_loss: 226.0145 - val_mae: 11.3923\n",
      "Epoch 143/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 224.3430 - mae: 11.4710 - val_loss: 228.9350 - val_mae: 11.5372\n",
      "Epoch 144/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.5042 - mae: 11.7170 - val_loss: 226.4455 - val_mae: 11.3957\n",
      "Epoch 145/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.5436 - mae: 11.6325 - val_loss: 226.1517 - val_mae: 11.4165\n",
      "Epoch 146/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 233.4130 - mae: 11.7097 - val_loss: 224.7995 - val_mae: 11.3309\n",
      "Epoch 147/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 228.8226 - mae: 11.5588 - val_loss: 225.4573 - val_mae: 11.3874\n",
      "Epoch 148/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 235.2701 - mae: 11.7641 - val_loss: 226.7855 - val_mae: 11.2670\n",
      "Epoch 149/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.0541 - mae: 11.6666 - val_loss: 229.4592 - val_mae: 11.4907\n",
      "Epoch 150/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 219.3028 - mae: 11.3164 - val_loss: 225.4140 - val_mae: 11.3566\n",
      "Epoch 151/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 227.8951 - mae: 11.6476 - val_loss: 229.2644 - val_mae: 11.4153\n",
      "Epoch 152/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 228.4387 - mae: 11.5497 - val_loss: 226.1245 - val_mae: 11.3643\n",
      "Epoch 153/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 230.0965 - mae: 11.6099 - val_loss: 228.1150 - val_mae: 11.4668\n",
      "Epoch 154/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 231.6096 - mae: 11.6446 - val_loss: 226.8310 - val_mae: 11.3468\n",
      "Epoch 155/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.8000 - mae: 11.5955 - val_loss: 225.8632 - val_mae: 11.4291\n",
      "Epoch 156/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 225.8076 - mae: 11.5608 - val_loss: 227.5708 - val_mae: 11.4272\n",
      "Epoch 157/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 225.2443 - mae: 11.4922 - val_loss: 228.9800 - val_mae: 11.5851\n",
      "Epoch 158/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 223.0148 - mae: 11.4604 - val_loss: 225.1879 - val_mae: 11.4399\n",
      "Epoch 159/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 235.3955 - mae: 11.7790 - val_loss: 224.3197 - val_mae: 11.3160\n",
      "Epoch 160/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.5376 - mae: 11.4289 - val_loss: 225.3746 - val_mae: 11.3325\n",
      "Epoch 161/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 228.2027 - mae: 11.5703 - val_loss: 226.7237 - val_mae: 11.4622\n",
      "Epoch 162/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.1096 - mae: 11.6090 - val_loss: 225.4230 - val_mae: 11.4233\n",
      "Epoch 163/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 233.9604 - mae: 11.7264 - val_loss: 228.6274 - val_mae: 11.4577\n",
      "Epoch 164/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.2384 - mae: 11.5586 - val_loss: 224.8096 - val_mae: 11.4098\n",
      "Epoch 165/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.6981 - mae: 11.6574 - val_loss: 225.8747 - val_mae: 11.3677\n",
      "Epoch 166/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.9106 - mae: 11.5777 - val_loss: 226.0317 - val_mae: 11.3652\n",
      "Epoch 167/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.7821 - mae: 11.6917 - val_loss: 229.3757 - val_mae: 11.4471\n",
      "Epoch 168/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 227.8978 - mae: 11.5995 - val_loss: 229.2608 - val_mae: 11.6352\n",
      "Epoch 169/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.5645 - mae: 11.6848 - val_loss: 226.2841 - val_mae: 11.2979\n",
      "Epoch 170/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 226.0677 - mae: 11.5100 - val_loss: 226.8999 - val_mae: 11.3970\n",
      "Epoch 171/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 226.7871 - mae: 11.5244 - val_loss: 227.2594 - val_mae: 11.3419\n",
      "Epoch 172/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 225.2374 - mae: 11.5096 - val_loss: 229.2704 - val_mae: 11.4955\n",
      "Epoch 173/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 224.5537 - mae: 11.4658 - val_loss: 226.1299 - val_mae: 11.4024\n",
      "Epoch 174/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 225.5478 - mae: 11.5621 - val_loss: 226.7294 - val_mae: 11.4304\n",
      "Epoch 175/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 223.9734 - mae: 11.4555 - val_loss: 225.5684 - val_mae: 11.3089\n",
      "Epoch 176/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 224.7545 - mae: 11.4500 - val_loss: 229.1216 - val_mae: 11.4719\n",
      "Epoch 177/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.2842 - mae: 11.6770 - val_loss: 226.7494 - val_mae: 11.4678\n",
      "Epoch 178/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 230.8234 - mae: 11.6282 - val_loss: 225.8685 - val_mae: 11.2845\n",
      "Epoch 179/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 231.1429 - mae: 11.6249 - val_loss: 224.8288 - val_mae: 11.3705\n",
      "Epoch 180/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 225.3433 - mae: 11.5072 - val_loss: 226.5388 - val_mae: 11.4341\n",
      "Epoch 181/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 224.7636 - mae: 11.4941 - val_loss: 224.3958 - val_mae: 11.3096\n",
      "Epoch 182/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 221.9643 - mae: 11.4241 - val_loss: 230.3172 - val_mae: 11.6041\n",
      "Epoch 183/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 224.2175 - mae: 11.4922 - val_loss: 225.6166 - val_mae: 11.4395\n",
      "Epoch 184/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 227.7524 - mae: 11.5527 - val_loss: 227.5921 - val_mae: 11.4988\n",
      "Epoch 185/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 227.4265 - mae: 11.5794 - val_loss: 225.8573 - val_mae: 11.3471\n",
      "Epoch 186/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 229.5454 - mae: 11.5829 - val_loss: 225.3559 - val_mae: 11.3500\n",
      "Epoch 187/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 230.7346 - mae: 11.6126 - val_loss: 224.0286 - val_mae: 11.3113\n",
      "Epoch 188/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 224.0632 - mae: 11.5260 - val_loss: 228.0199 - val_mae: 11.3922\n",
      "Epoch 189/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 223.0954 - mae: 11.4588 - val_loss: 233.9322 - val_mae: 11.6143\n",
      "Epoch 190/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 220.2855 - mae: 11.3914 - val_loss: 225.6805 - val_mae: 11.3576\n",
      "Epoch 191/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 227.6905 - mae: 11.5721 - val_loss: 224.5889 - val_mae: 11.3556\n",
      "Epoch 192/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 223.2807 - mae: 11.4491 - val_loss: 225.0594 - val_mae: 11.3762\n",
      "Epoch 193/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 232.9675 - mae: 11.6693 - val_loss: 228.9310 - val_mae: 11.5463\n",
      "Epoch 194/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 226.1612 - mae: 11.5858 - val_loss: 226.1543 - val_mae: 11.4296\n",
      "Epoch 195/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 230.9624 - mae: 11.6476 - val_loss: 224.4734 - val_mae: 11.3866\n",
      "Epoch 196/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 223.3676 - mae: 11.4440 - val_loss: 225.2833 - val_mae: 11.2857\n",
      "Epoch 197/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 225.0985 - mae: 11.5361 - val_loss: 225.0189 - val_mae: 11.3510\n",
      "Epoch 198/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 224.6435 - mae: 11.5312 - val_loss: 225.4926 - val_mae: 11.4168\n",
      "Epoch 199/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.7296 - mae: 11.5686 - val_loss: 223.4765 - val_mae: 11.2335\n",
      "Epoch 200/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 227.8013 - mae: 11.6064 - val_loss: 225.3796 - val_mae: 11.2981\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.7870 - mae: 11.1316\n",
      "Test Loss: 217.83615112304688, Test MAE: 11.162039756774902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(19,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Tolerance Accuracy (3): 19.04%\n",
      "Tolerance Accuracy (5): 30.96%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEMANTIC MODEL ( we take movie info(to understand context/ story line), which may also have influence on the movie result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Rotten_Tomatoes_Movies3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_title', 'movie_info', 'critics_consensus', 'rating', 'genre',\n",
       "       'directors', 'writers', 'cast', 'in_theaters_date', 'on_streaming_date',\n",
       "       'runtime_in_minutes', 'studio_name', 'tomatometer_status',\n",
       "       'tomatometer_rating', 'tomatometer_count', 'audience_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.18.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (4.24.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lashicr7\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lashicr7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.18.0 tf-keras transformers\n",
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "def compute_sentence_embeddings(texts):\n",
    "    \"\"\"Compute sentence embeddings for a list of texts.\"\"\"\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        if not text or pd.isna(text): \n",
    "            embeddings.append(np.zeros(sentence_model.get_sentence_embedding_dimension()))\n",
    "        else:\n",
    "            embedding = sentence_model.encode(text, show_progress_bar=False)\n",
    "            embeddings.append(embedding)\n",
    "    return np.array(embeddings)\n",
    "movie_info_embeddings = compute_sentence_embeddings(df['movie_info'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code for saving embeddings and reloading which can help in modular code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16638, 384)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('sentence_embeddings.txt', movie_info_embeddings, delimiter=' ')\n",
    "loaded_data = np.loadtxt('sentence_embeddings.txt', delimiter=' ')\n",
    "print(loaded_data.shape) \n",
    "print(np.array_equal( movie_info_embeddings, loaded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "reduced_embeddings = pca.fit_transform(movie_info_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16638, 218)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(reduced_embeddings)\n",
    "df = pd.concat([df, embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_info</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "      <th>cast</th>\n",
       "      <th>in_theaters_date</th>\n",
       "      <th>on_streaming_date</th>\n",
       "      <th>...</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>A teenager discovers he's the descendant of a ...</td>\n",
       "      <td>Though it may seem like just another Harry Pot...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>Craig Titley</td>\n",
       "      <td>Logan Lerman, Brandon T. Jackson, Alexandra Da...</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>6/29/2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006604</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.026795</td>\n",
       "      <td>-0.048007</td>\n",
       "      <td>0.068290</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>-0.007773</td>\n",
       "      <td>-0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Give</td>\n",
       "      <td>Kate has a lot on her mind. There's the ethics...</td>\n",
       "      <td>Nicole Holofcener's newest might seem slight i...</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>Catherine Keener, Amanda Peet, Oliver Platt, R...</td>\n",
       "      <td>4/30/2010</td>\n",
       "      <td>10/19/2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>0.028921</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>-0.002627</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>-0.046013</td>\n",
       "      <td>-0.028977</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>-0.063410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Blake Edwards' 10 stars Dudley Moore as George...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>Dudley Moore, Bo Derek, Julie Andrews, Robert ...</td>\n",
       "      <td>10/5/1979</td>\n",
       "      <td>8/27/1997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008803</td>\n",
       "      <td>-0.027856</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>-0.064736</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>-0.003647</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.003085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>A Puerto Rican youth is on trial for murder, a...</td>\n",
       "      <td>Sidney Lumet's feature debut is a superbly wri...</td>\n",
       "      <td>NR</td>\n",
       "      <td>Classics, Drama</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Reginald Rose</td>\n",
       "      <td>Martin Balsam, John Fiedler, Lee J. Cobb, E.G....</td>\n",
       "      <td>4/13/1957</td>\n",
       "      <td>3/6/2001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007631</td>\n",
       "      <td>0.036879</td>\n",
       "      <td>0.035361</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.044865</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>-0.022569</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>0.020489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>This 1954 Disney version of Jules Verne's 20,0...</td>\n",
       "      <td>One of Disney's finest live-action adventures,...</td>\n",
       "      <td>G</td>\n",
       "      <td>Action &amp; Adventure, Drama, Kids &amp; Family</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>Earl Felton</td>\n",
       "      <td>James Mason, Kirk Douglas, Paul Lukas, Peter L...</td>\n",
       "      <td>1/1/1954</td>\n",
       "      <td>5/20/2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>0.021618</td>\n",
       "      <td>0.015044</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>-0.053711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1                                        Please Give   \n",
       "2                                                 10   \n",
       "3                    12 Angry Men (Twelve Angry Men)   \n",
       "4                       20,000 Leagues Under The Sea   \n",
       "\n",
       "                                          movie_info  \\\n",
       "0  A teenager discovers he's the descendant of a ...   \n",
       "1  Kate has a lot on her mind. There's the ethics...   \n",
       "2  Blake Edwards' 10 stars Dudley Moore as George...   \n",
       "3  A Puerto Rican youth is on trial for murder, a...   \n",
       "4  This 1954 Disney version of Jules Verne's 20,0...   \n",
       "\n",
       "                                   critics_consensus rating  \\\n",
       "0  Though it may seem like just another Harry Pot...     PG   \n",
       "1  Nicole Holofcener's newest might seem slight i...      R   \n",
       "2                                                NaN      R   \n",
       "3  Sidney Lumet's feature debut is a superbly wri...     NR   \n",
       "4  One of Disney's finest live-action adventures,...      G   \n",
       "\n",
       "                                               genre          directors  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
       "1                                             Comedy  Nicole Holofcener   \n",
       "2                                    Comedy, Romance      Blake Edwards   \n",
       "3                                    Classics, Drama       Sidney Lumet   \n",
       "4           Action & Adventure, Drama, Kids & Family  Richard Fleischer   \n",
       "\n",
       "             writers                                               cast  \\\n",
       "0       Craig Titley  Logan Lerman, Brandon T. Jackson, Alexandra Da...   \n",
       "1  Nicole Holofcener  Catherine Keener, Amanda Peet, Oliver Platt, R...   \n",
       "2      Blake Edwards  Dudley Moore, Bo Derek, Julie Andrews, Robert ...   \n",
       "3      Reginald Rose  Martin Balsam, John Fiedler, Lee J. Cobb, E.G....   \n",
       "4        Earl Felton  James Mason, Kirk Douglas, Paul Lukas, Peter L...   \n",
       "\n",
       "  in_theaters_date on_streaming_date  ...       208       209       210  \\\n",
       "0        2/12/2010         6/29/2010  ... -0.006604  0.004451  0.010701   \n",
       "1        4/30/2010        10/19/2010  ... -0.017481  0.028921 -0.010660   \n",
       "2        10/5/1979         8/27/1997  ... -0.008803 -0.027856  0.000888   \n",
       "3        4/13/1957          3/6/2001  ... -0.007631  0.036879  0.035361   \n",
       "4         1/1/1954         5/20/2003  ...  0.000950  0.010259  0.021618   \n",
       "\n",
       "        211       212       213       214       215       216       217  \n",
       "0  0.027692  0.026795 -0.048007  0.068290  0.011586 -0.007773 -0.004174  \n",
       "1 -0.002627  0.022829 -0.046013 -0.028977 -0.035879  0.042951 -0.063410  \n",
       "2  0.020838  0.044571 -0.064736 -0.010670 -0.003647 -0.014654 -0.003085  \n",
       "3 -0.007004 -0.004631 -0.044865  0.002537 -0.022569  0.013458  0.020489  \n",
       "4  0.015044  0.001125  0.011272 -0.006171  0.036123  0.011871 -0.053711  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers using Z-Score method:\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "duplicate_rows = df[df.duplicated(keep=False)]\n",
    "df = df.drop_duplicates(keep=False).reset_index(drop=True)\n",
    "df = df.dropna(subset=['genre']).reset_index(drop=True)\n",
    "df = df.dropna(subset=['audience_rating']).reset_index(drop=True)\n",
    "df = df.dropna(subset=['in_theaters_date', 'on_streaming_date'], how='all').reset_index(drop=True)\n",
    "\n",
    "\n",
    "runtime_median = df['runtime_in_minutes'].median()\n",
    "df['runtime_in_minutes'].fillna(runtime_median, inplace=True)\n",
    "runtime_non_null = df['runtime_in_minutes']\n",
    "z_scores = zscore(runtime_non_null)\n",
    "outliers_z = runtime_non_null[abs(z_scores) > 3]\n",
    "print(\"Outliers using Z-Score method:\")\n",
    "print(len(outliers_z))\n",
    "outlier_mask = abs(z_scores) > 3\n",
    "df = df[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "unique_genres = set()\n",
    "for i in range(len(df)):\n",
    "    genres = df['genre'].loc[i].split(\",\")\n",
    "    for j in genres:\n",
    "        unique_genres.add(j.strip().lower())\n",
    "unique_genres = sorted(unique_genres)\n",
    "for genre in unique_genres:\n",
    "    df[genre] = df['genre'].apply(lambda x: 1 if genre in x.strip().lower() else 0)\n",
    "\n",
    "\n",
    "df['rating'] = df['rating'].apply(lambda x: x[:-1] if x.endswith(')') else x)\n",
    "\n",
    "\n",
    "df['in_theaters_date'] = pd.to_datetime(df['in_theaters_date'], errors='coerce')\n",
    "df['on_streaming_date'] = pd.to_datetime(df['on_streaming_date'], errors='coerce')\n",
    "df.loc[df['in_theaters_date'].isna() & df['on_streaming_date'].notna(), 'in_theaters_date'] = df['on_streaming_date']\n",
    "df['theatre_year'] = df['in_theaters_date'].dt.year\n",
    "df['stream_year'] = df['on_streaming_date'].dt.year\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Rotten', 'Certified Fresh', 'Fresh']])\n",
    "df['status'] = ordinal_encoder.fit_transform(df[['tomatometer_status']])\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['PG', 'R', 'NR', 'G', 'PG-13', 'NC17']]) \n",
    "df['rating_encoded'] = ordinal_encoder.fit_transform(df[['rating']])\n",
    "\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df['runtime_in_minutes_scaled'] = standard_scaler.fit_transform(df[['runtime_in_minutes']])\n",
    "df[['tomatometer_count_scaled', 'theatre_year_scaled', 'stream_year_scaled','tomatometer_rating_scaled']] = min_max_scaler.fit_transform(df[['tomatometer_count', 'theatre_year', 'stream_year', 'tomatometer_rating']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>Science Fiction &amp; Fantasy</th>\n",
       "      <th>Special Interest</th>\n",
       "      <th>Television</th>\n",
       "      <th>Western</th>\n",
       "      <th>status</th>\n",
       "      <th>rating_encoded</th>\n",
       "      <th>runtime_in_minutes_scaled</th>\n",
       "      <th>tomatometer_count_scaled</th>\n",
       "      <th>theatre_year_scaled</th>\n",
       "      <th>tomatometer_rating_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>-0.018757</td>\n",
       "      <td>0.232074</td>\n",
       "      <td>-0.023098</td>\n",
       "      <td>0.096871</td>\n",
       "      <td>-0.238822</td>\n",
       "      <td>0.066859</td>\n",
       "      <td>0.068015</td>\n",
       "      <td>-0.065756</td>\n",
       "      <td>0.086425</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.093671</td>\n",
       "      <td>0.282520</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.406907</td>\n",
       "      <td>0.090574</td>\n",
       "      <td>0.059328</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>-0.067305</td>\n",
       "      <td>-0.067004</td>\n",
       "      <td>0.089533</td>\n",
       "      <td>-0.052919</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.686755</td>\n",
       "      <td>0.274390</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>-0.227193</td>\n",
       "      <td>0.168880</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>-0.109269</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.090073</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940910</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.087041</td>\n",
       "      <td>-0.140239</td>\n",
       "      <td>-0.153896</td>\n",
       "      <td>0.030524</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>-0.043095</td>\n",
       "      <td>0.095758</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.396100</td>\n",
       "      <td>0.093496</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.274508</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>0.288013</td>\n",
       "      <td>-0.027486</td>\n",
       "      <td>-0.118240</td>\n",
       "      <td>0.115243</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.165950</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.464089</td>\n",
       "      <td>0.044715</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   audience_rating         0         1         2         3         4  \\\n",
       "0             53.0 -0.018757  0.232074 -0.023098  0.096871 -0.238822   \n",
       "1             64.0  0.406907  0.090574  0.059328  0.035007  0.028385   \n",
       "2             53.0  0.057845 -0.227193  0.168880  0.014530 -0.109269   \n",
       "3             97.0 -0.087041 -0.140239 -0.153896  0.030524  0.105706   \n",
       "4             74.0 -0.274508  0.044719  0.288013 -0.027486 -0.118240   \n",
       "\n",
       "          5         6         7         8  ...  Science Fiction & Fantasy  \\\n",
       "0  0.066859  0.068015 -0.065756  0.086425  ...                          0   \n",
       "1 -0.067305 -0.067004  0.089533 -0.052919  ...                          0   \n",
       "2  0.008475  0.046020  0.090073 -0.059194  ...                          0   \n",
       "3  0.041612  0.102906 -0.043095  0.095758  ...                          0   \n",
       "4  0.115243  0.061658  0.165950  0.014132  ...                          0   \n",
       "\n",
       "   Special Interest  Television  Western  status  rating_encoded  \\\n",
       "0                 0           0        0     0.0             0.0   \n",
       "1                 0           0        0     1.0             1.0   \n",
       "2                 0           0        0     2.0             1.0   \n",
       "3                 0           0        0     1.0             2.0   \n",
       "4                 0           0        0     2.0             3.0   \n",
       "\n",
       "   runtime_in_minutes_scaled  tomatometer_count_scaled  theatre_year_scaled  \\\n",
       "0                  -1.093671                  0.282520             0.913462   \n",
       "1                  -0.686755                  0.274390             0.913462   \n",
       "2                   0.940910                  0.034553             0.615385   \n",
       "3                  -0.396100                  0.093496             0.403846   \n",
       "4                   1.464089                  0.044715             0.375000   \n",
       "\n",
       "   tomatometer_rating_scaled  \n",
       "0                       0.49  \n",
       "1                       0.86  \n",
       "2                       0.68  \n",
       "3                       1.00  \n",
       "4                       0.89  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['movie_title', 'movie_info', 'critics_consensus', 'directors', \n",
    "                   'writers', 'cast', 'in_theaters_date', 'on_streaming_date', 'studio_name', 'genre', 'tomatometer_status', 'rating', 'runtime_in_minutes', 'tomatometer_count','theatre_year', 'stream_year','stream_year_scaled','tomatometer_rating']\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16215, 87)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('audience_rating', axis=1)  \n",
    "y = df['audience_rating'] \n",
    "\n",
    "X_reduced = pca.fit_transform(X)\n",
    "print(X_reduced.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lashicr7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(87,)),  # First hidden layer\n",
    "    BatchNormalization(),                               # Normalize activations\n",
    "    Dropout(0.3),                                       # Dropout for regularization\n",
    "    \n",
    "    Dense(32, activation='relu'),                      # Third hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')                       # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mse',                              \n",
    "              metrics=['mae'])                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> \n",
       "\n",
       " batch_normalization_29           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \n",
       "\n",
       " batch_normalization_30           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_42 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m5,632\u001b[0m \n",
       "\n",
       " batch_normalization_29           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                        \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_29 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_43 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m2,080\u001b[0m \n",
       "\n",
       " batch_normalization_30           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                        \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_30 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_44 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m33\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,129</span> (31.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,129\u001b[0m (31.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3844.7939 - mae: 59.1439 - val_loss: 2967.7920 - val_mae: 52.3058 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2674.1475 - mae: 49.3559 - val_loss: 1358.2827 - val_mae: 34.2680 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1076.9231 - mae: 29.3594 - val_loss: 383.2626 - val_mae: 16.1697 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.3310 - mae: 15.3589 - val_loss: 191.3734 - val_mae: 11.0638 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 242.1050 - mae: 12.3163 - val_loss: 185.7095 - val_mae: 10.9060 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 241.9524 - mae: 12.2636 - val_loss: 184.0735 - val_mae: 10.7708 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 231.4498 - mae: 12.0841 - val_loss: 181.2871 - val_mae: 10.6418 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 233.0400 - mae: 12.1213 - val_loss: 182.0348 - val_mae: 10.7642 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 222.2945 - mae: 11.8278 - val_loss: 181.1111 - val_mae: 10.6857 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 224.7913 - mae: 11.9453 - val_loss: 180.0448 - val_mae: 10.6757 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 214.8481 - mae: 11.6229 - val_loss: 180.2704 - val_mae: 10.6835 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 217.9576 - mae: 11.7762 - val_loss: 180.8611 - val_mae: 10.6468 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 218.4217 - mae: 11.7715 - val_loss: 180.0395 - val_mae: 10.5783 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 226.2397 - mae: 11.9685 - val_loss: 178.7066 - val_mae: 10.6287 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 214.6378 - mae: 11.6075 - val_loss: 179.6093 - val_mae: 10.6075 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 215.3688 - mae: 11.5897 - val_loss: 179.1186 - val_mae: 10.6346 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 220.3660 - mae: 11.7223 - val_loss: 178.5206 - val_mae: 10.5771 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 206.9422 - mae: 11.4861 - val_loss: 178.8848 - val_mae: 10.5446 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 216.1951 - mae: 11.7040 - val_loss: 178.2086 - val_mae: 10.5465 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 211.0606 - mae: 11.5498 - val_loss: 179.8495 - val_mae: 10.6007 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 206.4554 - mae: 11.3527 - val_loss: 180.8163 - val_mae: 10.6879 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 206.1123 - mae: 11.4343 - val_loss: 178.6606 - val_mae: 10.5691 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 207.7473 - mae: 11.4285 - val_loss: 179.9125 - val_mae: 10.6155 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 200.8470 - mae: 11.2748 - val_loss: 179.0704 - val_mae: 10.5922 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 197.0737 - mae: 11.1409 - val_loss: 179.4611 - val_mae: 10.5641 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 198.5178 - mae: 11.1539 - val_loss: 179.4718 - val_mae: 10.5911 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 185.8277 - mae: 10.8159 - val_loss: 179.1491 - val_mae: 10.5456 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196.3623 - mae: 11.1446 - val_loss: 179.4476 - val_mae: 10.5807 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 197.9611 - mae: 11.1718 - val_loss: 179.0689 - val_mae: 10.5265 - learning_rate: 5.0000e-04\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 181.0759 - mae: 10.5875\n",
      "Test Loss: 184.6675567626953, Test MAE: 10.605928421020508\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Tolerance Accuracy (3): 18.01%\n",
      "Tolerance Accuracy (5): 29.88%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "MAE: 10.861464848313991\n",
      "MSE: 190.9694591325847\n",
      "R Score: 0.5453694095612178\n",
      "Rounded Accuracy: 0.027135368485969782\n",
      "Tolerance Accuracy (3): 16.77%\n",
      "Tolerance Accuracy (5): 28.37%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R Score: {r2}\")\n",
    "\n",
    "y_pred_rounded = np.round(y_pred)\n",
    "rounded_accuracy = (y_pred_rounded == y_test).mean()\n",
    "print(f\"Rounded Accuracy: {rounded_accuracy}\")\n",
    "\n",
    "tolerance_3_accuracy = ((np.abs(y_pred - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lashicr7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
       "\n",
       " batch_normalization_8            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,333</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_24 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                        \u001b[38;5;34m320\u001b[0m \n",
       "\n",
       " batch_normalization_8            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                         \u001b[38;5;34m64\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dense_25 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                        \u001b[38;5;34m544\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_26 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                     \u001b[38;5;34m3,333\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,261</span> (16.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,261\u001b[0m (16.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,229</span> (16.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,229\u001b[0m (16.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0223 - loss: 4.4194 - val_accuracy: 0.0464 - val_loss: 4.2434\n",
      "Epoch 2/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0533 - loss: 4.0919 - val_accuracy: 0.0745 - val_loss: 3.9482\n",
      "Epoch 3/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0772 - loss: 3.9426 - val_accuracy: 0.0935 - val_loss: 3.8559\n",
      "Epoch 4/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0916 - loss: 3.8729 - val_accuracy: 0.0943 - val_loss: 3.8636\n",
      "Epoch 5/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 3.8388 - val_accuracy: 0.1076 - val_loss: 3.8081\n",
      "Epoch 6/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1079 - loss: 3.8045 - val_accuracy: 0.1034 - val_loss: 3.8120\n",
      "Epoch 7/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1055 - loss: 3.7805 - val_accuracy: 0.1106 - val_loss: 3.7480\n",
      "Epoch 8/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1127 - loss: 3.7458 - val_accuracy: 0.1104 - val_loss: 3.7283\n",
      "Epoch 9/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1164 - loss: 3.7455 - val_accuracy: 0.1090 - val_loss: 3.7235\n",
      "Epoch 10/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1177 - loss: 3.7317 - val_accuracy: 0.1176 - val_loss: 3.6924\n",
      "Epoch 11/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1237 - loss: 3.7001 - val_accuracy: 0.1253 - val_loss: 3.6760\n",
      "Epoch 12/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1195 - loss: 3.7008 - val_accuracy: 0.1232 - val_loss: 3.6669\n",
      "Epoch 13/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1263 - loss: 3.6824 - val_accuracy: 0.1162 - val_loss: 3.6905\n",
      "Epoch 14/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1237 - loss: 3.6803 - val_accuracy: 0.1333 - val_loss: 3.6669\n",
      "Epoch 15/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1258 - loss: 3.6709 - val_accuracy: 0.1251 - val_loss: 3.6600\n",
      "Epoch 16/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1262 - loss: 3.6785 - val_accuracy: 0.1198 - val_loss: 3.6865\n",
      "Epoch 17/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1291 - loss: 3.6576 - val_accuracy: 0.1327 - val_loss: 3.6402\n",
      "Epoch 18/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1317 - loss: 3.6437 - val_accuracy: 0.1357 - val_loss: 3.6461\n",
      "Epoch 19/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1323 - loss: 3.6462 - val_accuracy: 0.1333 - val_loss: 3.6397\n",
      "Epoch 20/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1296 - loss: 3.6605 - val_accuracy: 0.1347 - val_loss: 3.6598\n",
      "Epoch 21/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1390 - loss: 3.6273 - val_accuracy: 0.1293 - val_loss: 3.6982\n",
      "Epoch 22/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1308 - loss: 3.6270 - val_accuracy: 0.1345 - val_loss: 3.6608\n",
      "Epoch 23/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1335 - loss: 3.6551 - val_accuracy: 0.1321 - val_loss: 3.6701\n",
      "Epoch 24/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1359 - loss: 3.6265 - val_accuracy: 0.1427 - val_loss: 3.6094\n",
      "Epoch 25/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1330 - loss: 3.6013 - val_accuracy: 0.1389 - val_loss: 3.6349\n",
      "Epoch 26/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1293 - loss: 3.6380 - val_accuracy: 0.1395 - val_loss: 3.6313\n",
      "Epoch 27/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1369 - loss: 3.6038 - val_accuracy: 0.1385 - val_loss: 3.6100\n",
      "Epoch 28/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1331 - loss: 3.6161 - val_accuracy: 0.1427 - val_loss: 3.6160\n",
      "Epoch 29/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1382 - loss: 3.5958 - val_accuracy: 0.1437 - val_loss: 3.6288\n",
      "Epoch 30/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1364 - loss: 3.5937 - val_accuracy: 0.1477 - val_loss: 3.6098\n",
      "Epoch 31/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1363 - loss: 3.6166 - val_accuracy: 0.1461 - val_loss: 3.6018\n",
      "Epoch 32/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1397 - loss: 3.5937 - val_accuracy: 0.1473 - val_loss: 3.5901\n",
      "Epoch 33/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1364 - loss: 3.5949 - val_accuracy: 0.1499 - val_loss: 3.5915\n",
      "Epoch 34/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1334 - loss: 3.6042 - val_accuracy: 0.1495 - val_loss: 3.5923\n",
      "Epoch 35/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1411 - loss: 3.5949 - val_accuracy: 0.1517 - val_loss: 3.5985\n",
      "Epoch 36/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1375 - loss: 3.6011 - val_accuracy: 0.1459 - val_loss: 3.5986\n",
      "Epoch 37/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1388 - loss: 3.5910 - val_accuracy: 0.1399 - val_loss: 3.6140\n",
      "Epoch 38/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1382 - loss: 3.5990 - val_accuracy: 0.1517 - val_loss: 3.5892\n",
      "Epoch 39/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1384 - loss: 3.5913 - val_accuracy: 0.1527 - val_loss: 3.5837\n",
      "Epoch 40/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1410 - loss: 3.5867 - val_accuracy: 0.1459 - val_loss: 3.6095\n",
      "Epoch 41/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1421 - loss: 3.5896 - val_accuracy: 0.1411 - val_loss: 3.6155\n",
      "Epoch 42/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1393 - loss: 3.6012 - val_accuracy: 0.1519 - val_loss: 3.5888\n",
      "Epoch 43/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1390 - loss: 3.5858 - val_accuracy: 0.1459 - val_loss: 3.6044\n",
      "Epoch 44/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1435 - loss: 3.5834 - val_accuracy: 0.1493 - val_loss: 3.6320\n",
      "Epoch 45/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1396 - loss: 3.5770 - val_accuracy: 0.1481 - val_loss: 3.6062\n",
      "Epoch 46/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1426 - loss: 3.5776 - val_accuracy: 0.1471 - val_loss: 3.6225\n",
      "Epoch 47/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1492 - loss: 3.5627 - val_accuracy: 0.1489 - val_loss: 3.6028\n",
      "Epoch 48/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1425 - loss: 3.5692 - val_accuracy: 0.1578 - val_loss: 3.5834\n",
      "Epoch 49/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1423 - loss: 3.5758 - val_accuracy: 0.1560 - val_loss: 3.5720\n",
      "Epoch 50/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1452 - loss: 3.5774 - val_accuracy: 0.1495 - val_loss: 3.5998\n",
      "Epoch 51/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1429 - loss: 3.5661 - val_accuracy: 0.1525 - val_loss: 3.5821\n",
      "Epoch 52/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1457 - loss: 3.5528 - val_accuracy: 0.1477 - val_loss: 3.5895\n",
      "Epoch 53/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1444 - loss: 3.5932 - val_accuracy: 0.1435 - val_loss: 3.6110\n",
      "Epoch 54/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1400 - loss: 3.5674 - val_accuracy: 0.1556 - val_loss: 3.5696\n",
      "Epoch 55/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1398 - loss: 3.5716 - val_accuracy: 0.1495 - val_loss: 3.5819\n",
      "Epoch 56/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1460 - loss: 3.5554 - val_accuracy: 0.1489 - val_loss: 3.5854\n",
      "Epoch 57/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1451 - loss: 3.5667 - val_accuracy: 0.1582 - val_loss: 3.5655\n",
      "Epoch 58/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1472 - loss: 3.5647 - val_accuracy: 0.1528 - val_loss: 3.5904\n",
      "Epoch 59/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1438 - loss: 3.5610 - val_accuracy: 0.1491 - val_loss: 3.5906\n",
      "Epoch 60/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1448 - loss: 3.5661 - val_accuracy: 0.1429 - val_loss: 3.6194\n",
      "Epoch 61/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1456 - loss: 3.5596 - val_accuracy: 0.1598 - val_loss: 3.5657\n",
      "Epoch 62/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1495 - loss: 3.5539 - val_accuracy: 0.1534 - val_loss: 3.5601\n",
      "Epoch 63/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1457 - loss: 3.5596 - val_accuracy: 0.1513 - val_loss: 3.6159\n",
      "Epoch 64/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1478 - loss: 3.5693 - val_accuracy: 0.1556 - val_loss: 3.5715\n",
      "Epoch 65/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1457 - loss: 3.5610 - val_accuracy: 0.1530 - val_loss: 3.5750\n",
      "Epoch 66/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1454 - loss: 3.5608 - val_accuracy: 0.1471 - val_loss: 3.5890\n",
      "Epoch 67/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1435 - loss: 3.5715 - val_accuracy: 0.1469 - val_loss: 3.5833\n",
      "Epoch 68/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1555 - loss: 3.5462 - val_accuracy: 0.1485 - val_loss: 3.5822\n",
      "Epoch 69/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1462 - loss: 3.5608 - val_accuracy: 0.1558 - val_loss: 3.5530\n",
      "Epoch 70/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1457 - loss: 3.5437 - val_accuracy: 0.1570 - val_loss: 3.5707\n",
      "Epoch 71/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1471 - loss: 3.5600 - val_accuracy: 0.1572 - val_loss: 3.5684\n",
      "Epoch 72/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1484 - loss: 3.5559 - val_accuracy: 0.1568 - val_loss: 3.5749\n",
      "Epoch 73/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1487 - loss: 3.5611 - val_accuracy: 0.1548 - val_loss: 3.5739\n",
      "Epoch 74/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1519 - loss: 3.5475 - val_accuracy: 0.1505 - val_loss: 3.5975\n",
      "Epoch 75/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1458 - loss: 3.5537 - val_accuracy: 0.1501 - val_loss: 3.5820\n",
      "Epoch 76/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1481 - loss: 3.5499 - val_accuracy: 0.1578 - val_loss: 3.5597\n",
      "Epoch 77/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1483 - loss: 3.5405 - val_accuracy: 0.1570 - val_loss: 3.5583\n",
      "Epoch 78/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1540 - loss: 3.5457 - val_accuracy: 0.1515 - val_loss: 3.5673\n",
      "Epoch 79/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1516 - loss: 3.5412 - val_accuracy: 0.1546 - val_loss: 3.5675\n",
      "Epoch 80/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1527 - loss: 3.5594 - val_accuracy: 0.1493 - val_loss: 3.5853\n",
      "Epoch 81/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1488 - loss: 3.5459 - val_accuracy: 0.1509 - val_loss: 3.5669\n",
      "Epoch 82/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1488 - loss: 3.5461 - val_accuracy: 0.1534 - val_loss: 3.5765\n",
      "Epoch 83/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1507 - loss: 3.5429 - val_accuracy: 0.1588 - val_loss: 3.5573\n",
      "Epoch 84/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1513 - loss: 3.5386 - val_accuracy: 0.1523 - val_loss: 3.5673\n",
      "Epoch 85/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1519 - loss: 3.5267 - val_accuracy: 0.1517 - val_loss: 3.5639\n",
      "Epoch 86/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1499 - loss: 3.5460 - val_accuracy: 0.1538 - val_loss: 3.5680\n",
      "Epoch 87/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1517 - loss: 3.5407 - val_accuracy: 0.1564 - val_loss: 3.5517\n",
      "Epoch 88/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1524 - loss: 3.5272 - val_accuracy: 0.1562 - val_loss: 3.5415\n",
      "Epoch 89/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1526 - loss: 3.5336 - val_accuracy: 0.1540 - val_loss: 3.5600\n",
      "Epoch 90/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1508 - loss: 3.5407 - val_accuracy: 0.1558 - val_loss: 3.5525\n",
      "Epoch 91/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1463 - loss: 3.5562 - val_accuracy: 0.1590 - val_loss: 3.5427\n",
      "Epoch 92/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1580 - loss: 3.5279 - val_accuracy: 0.1517 - val_loss: 3.5659\n",
      "Epoch 93/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1467 - loss: 3.5436 - val_accuracy: 0.1525 - val_loss: 3.5891\n",
      "Epoch 94/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1513 - loss: 3.5452 - val_accuracy: 0.1576 - val_loss: 3.5584\n",
      "Epoch 95/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1531 - loss: 3.5334 - val_accuracy: 0.1473 - val_loss: 3.5741\n",
      "Epoch 96/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1509 - loss: 3.5481 - val_accuracy: 0.1525 - val_loss: 3.5594\n",
      "Epoch 97/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1490 - loss: 3.5503 - val_accuracy: 0.1596 - val_loss: 3.5546\n",
      "Epoch 98/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1470 - loss: 3.5470 - val_accuracy: 0.1592 - val_loss: 3.5450\n",
      "Epoch 99/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1505 - loss: 3.5366 - val_accuracy: 0.1582 - val_loss: 3.5523\n",
      "Epoch 100/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1481 - loss: 3.5569 - val_accuracy: 0.1483 - val_loss: 3.6073\n",
      "Epoch 101/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1522 - loss: 3.5383 - val_accuracy: 0.1554 - val_loss: 3.5505\n",
      "Epoch 102/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1491 - loss: 3.5354 - val_accuracy: 0.1582 - val_loss: 3.5386\n",
      "Epoch 103/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1595 - loss: 3.5235 - val_accuracy: 0.1566 - val_loss: 3.5447\n",
      "Epoch 104/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1530 - loss: 3.5322 - val_accuracy: 0.1517 - val_loss: 3.5629\n",
      "Epoch 105/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1469 - loss: 3.5594 - val_accuracy: 0.1564 - val_loss: 3.5448\n",
      "Epoch 106/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1574 - loss: 3.5191 - val_accuracy: 0.1564 - val_loss: 3.5559\n",
      "Epoch 107/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1482 - loss: 3.5480 - val_accuracy: 0.1560 - val_loss: 3.5542\n",
      "Epoch 108/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1536 - loss: 3.5327 - val_accuracy: 0.1546 - val_loss: 3.5776\n",
      "Epoch 109/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1538 - loss: 3.5203 - val_accuracy: 0.1614 - val_loss: 3.5652\n",
      "Epoch 110/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1496 - loss: 3.5489 - val_accuracy: 0.1566 - val_loss: 3.5818\n",
      "Epoch 111/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1503 - loss: 3.5470 - val_accuracy: 0.1534 - val_loss: 3.5596\n",
      "Epoch 112/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1508 - loss: 3.5402 - val_accuracy: 0.1596 - val_loss: 3.5541\n",
      "Epoch 113/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1517 - loss: 3.5306 - val_accuracy: 0.1600 - val_loss: 3.5718\n",
      "Epoch 114/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1550 - loss: 3.5229 - val_accuracy: 0.1542 - val_loss: 3.5591\n",
      "Epoch 115/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1481 - loss: 3.5475 - val_accuracy: 0.1473 - val_loss: 3.5893\n",
      "Epoch 116/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1483 - loss: 3.5420 - val_accuracy: 0.1580 - val_loss: 3.5747\n",
      "Epoch 117/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1492 - loss: 3.5429 - val_accuracy: 0.1570 - val_loss: 3.5547\n",
      "Epoch 118/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1572 - loss: 3.5175 - val_accuracy: 0.1578 - val_loss: 3.5544\n",
      "Epoch 119/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1514 - loss: 3.5355 - val_accuracy: 0.1505 - val_loss: 3.5836\n",
      "Epoch 120/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1542 - loss: 3.5285 - val_accuracy: 0.1564 - val_loss: 3.5434\n",
      "Epoch 121/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1501 - loss: 3.5472 - val_accuracy: 0.1604 - val_loss: 3.5419\n",
      "Epoch 122/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1543 - loss: 3.5492 - val_accuracy: 0.1572 - val_loss: 3.5776\n",
      "Epoch 123/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1578 - loss: 3.5267 - val_accuracy: 0.1594 - val_loss: 3.5592\n",
      "Epoch 124/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1544 - loss: 3.5356 - val_accuracy: 0.1576 - val_loss: 3.5435\n",
      "Epoch 125/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1514 - loss: 3.5400 - val_accuracy: 0.1546 - val_loss: 3.5390\n",
      "Epoch 126/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1519 - loss: 3.5315 - val_accuracy: 0.1590 - val_loss: 3.5470\n",
      "Epoch 127/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1538 - loss: 3.5370 - val_accuracy: 0.1656 - val_loss: 3.5469\n",
      "Epoch 128/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1534 - loss: 3.5273 - val_accuracy: 0.1505 - val_loss: 3.5786\n",
      "Epoch 129/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1543 - loss: 3.5193 - val_accuracy: 0.1588 - val_loss: 3.5670\n",
      "Epoch 130/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1559 - loss: 3.5176 - val_accuracy: 0.1576 - val_loss: 3.5456\n",
      "Epoch 131/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1525 - loss: 3.5197 - val_accuracy: 0.1614 - val_loss: 3.5550\n",
      "Epoch 132/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1559 - loss: 3.5163 - val_accuracy: 0.1501 - val_loss: 3.5659\n",
      "Epoch 133/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1499 - loss: 3.5356 - val_accuracy: 0.1638 - val_loss: 3.5293\n",
      "Epoch 134/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1555 - loss: 3.5220 - val_accuracy: 0.1598 - val_loss: 3.5544\n",
      "Epoch 135/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1554 - loss: 3.5279 - val_accuracy: 0.1564 - val_loss: 3.5454\n",
      "Epoch 136/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1508 - loss: 3.5307 - val_accuracy: 0.1548 - val_loss: 3.5591\n",
      "Epoch 137/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1541 - loss: 3.5264 - val_accuracy: 0.1598 - val_loss: 3.5518\n",
      "Epoch 138/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1561 - loss: 3.5294 - val_accuracy: 0.1610 - val_loss: 3.5409\n",
      "Epoch 139/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1487 - loss: 3.5420 - val_accuracy: 0.1624 - val_loss: 3.5324\n",
      "Epoch 140/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1541 - loss: 3.5260 - val_accuracy: 0.1618 - val_loss: 3.5401\n",
      "Epoch 141/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1543 - loss: 3.5158 - val_accuracy: 0.1584 - val_loss: 3.5454\n",
      "Epoch 142/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1493 - loss: 3.5388 - val_accuracy: 0.1566 - val_loss: 3.5598\n",
      "Epoch 143/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1562 - loss: 3.5182 - val_accuracy: 0.1626 - val_loss: 3.5351\n",
      "Epoch 144/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1574 - loss: 3.5310 - val_accuracy: 0.1568 - val_loss: 3.5391\n",
      "Epoch 145/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1559 - loss: 3.5285 - val_accuracy: 0.1618 - val_loss: 3.5370\n",
      "Epoch 146/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1504 - loss: 3.5364 - val_accuracy: 0.1596 - val_loss: 3.5558\n",
      "Epoch 147/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1531 - loss: 3.5387 - val_accuracy: 0.1622 - val_loss: 3.5332\n",
      "Epoch 148/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1508 - loss: 3.5303 - val_accuracy: 0.1650 - val_loss: 3.5332\n",
      "Epoch 149/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1515 - loss: 3.5399 - val_accuracy: 0.1624 - val_loss: 3.5331\n",
      "Epoch 150/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1557 - loss: 3.5104 - val_accuracy: 0.1618 - val_loss: 3.5542\n",
      "Epoch 151/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1569 - loss: 3.5209 - val_accuracy: 0.1616 - val_loss: 3.5398\n",
      "Epoch 152/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1564 - loss: 3.5214 - val_accuracy: 0.1612 - val_loss: 3.5838\n",
      "Epoch 153/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1518 - loss: 3.5257 - val_accuracy: 0.1608 - val_loss: 3.5307\n",
      "Epoch 154/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1592 - loss: 3.5127 - val_accuracy: 0.1622 - val_loss: 3.5254\n",
      "Epoch 155/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1554 - loss: 3.5256 - val_accuracy: 0.1540 - val_loss: 3.5708\n",
      "Epoch 156/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1537 - loss: 3.5168 - val_accuracy: 0.1600 - val_loss: 3.5696\n",
      "Epoch 157/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1569 - loss: 3.5169 - val_accuracy: 0.1642 - val_loss: 3.5377\n",
      "Epoch 158/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1498 - loss: 3.5240 - val_accuracy: 0.1630 - val_loss: 3.5303\n",
      "Epoch 159/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1533 - loss: 3.5246 - val_accuracy: 0.1580 - val_loss: 3.5581\n",
      "Epoch 160/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1569 - loss: 3.5196 - val_accuracy: 0.1638 - val_loss: 3.5264\n",
      "Epoch 161/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1551 - loss: 3.5199 - val_accuracy: 0.1576 - val_loss: 3.5529\n",
      "Epoch 162/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1552 - loss: 3.5308 - val_accuracy: 0.1626 - val_loss: 3.5249\n",
      "Epoch 163/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1561 - loss: 3.5123 - val_accuracy: 0.1652 - val_loss: 3.5264\n",
      "Epoch 164/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1568 - loss: 3.5274 - val_accuracy: 0.1704 - val_loss: 3.5414\n",
      "Epoch 165/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1540 - loss: 3.5247 - val_accuracy: 0.1612 - val_loss: 3.5400\n",
      "Epoch 166/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1584 - loss: 3.5226 - val_accuracy: 0.1658 - val_loss: 3.5488\n",
      "Epoch 167/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1591 - loss: 3.5097 - val_accuracy: 0.1644 - val_loss: 3.5419\n",
      "Epoch 168/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1577 - loss: 3.5332 - val_accuracy: 0.1668 - val_loss: 3.5287\n",
      "Epoch 169/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1591 - loss: 3.5131 - val_accuracy: 0.1600 - val_loss: 3.5383\n",
      "Epoch 170/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1523 - loss: 3.5219 - val_accuracy: 0.1566 - val_loss: 3.5481\n",
      "Epoch 171/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1532 - loss: 3.5382 - val_accuracy: 0.1608 - val_loss: 3.5359\n",
      "Epoch 172/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1562 - loss: 3.5229 - val_accuracy: 0.1640 - val_loss: 3.5254\n",
      "Epoch 173/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1552 - loss: 3.5318 - val_accuracy: 0.1616 - val_loss: 3.5411\n",
      "Epoch 174/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1551 - loss: 3.5355 - val_accuracy: 0.1562 - val_loss: 3.5563\n",
      "Epoch 175/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1564 - loss: 3.5153 - val_accuracy: 0.1616 - val_loss: 3.5256\n",
      "Epoch 176/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1565 - loss: 3.5149 - val_accuracy: 0.1678 - val_loss: 3.5243\n",
      "Epoch 177/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1591 - loss: 3.5217 - val_accuracy: 0.1586 - val_loss: 3.5435\n",
      "Epoch 178/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1573 - loss: 3.5095 - val_accuracy: 0.1602 - val_loss: 3.5349\n",
      "Epoch 179/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1513 - loss: 3.5384 - val_accuracy: 0.1628 - val_loss: 3.5526\n",
      "Epoch 180/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1587 - loss: 3.5058 - val_accuracy: 0.1628 - val_loss: 3.5413\n",
      "Epoch 181/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1547 - loss: 3.5127 - val_accuracy: 0.1632 - val_loss: 3.5343\n",
      "Epoch 182/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1544 - loss: 3.5460 - val_accuracy: 0.1652 - val_loss: 3.5325\n",
      "Epoch 183/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1580 - loss: 3.5258 - val_accuracy: 0.1556 - val_loss: 3.5604\n",
      "Epoch 184/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1520 - loss: 3.5398 - val_accuracy: 0.1656 - val_loss: 3.5256\n",
      "Epoch 185/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1599 - loss: 3.5154 - val_accuracy: 0.1648 - val_loss: 3.5487\n",
      "Epoch 186/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1532 - loss: 3.5212 - val_accuracy: 0.1600 - val_loss: 3.5268\n",
      "Epoch 187/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1587 - loss: 3.5074 - val_accuracy: 0.1658 - val_loss: 3.5282\n",
      "Epoch 188/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1538 - loss: 3.5217 - val_accuracy: 0.1650 - val_loss: 3.5273\n",
      "Epoch 189/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1579 - loss: 3.5051 - val_accuracy: 0.1608 - val_loss: 3.5531\n",
      "Epoch 190/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1497 - loss: 3.5286 - val_accuracy: 0.1638 - val_loss: 3.5325\n",
      "Epoch 191/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1576 - loss: 3.5101 - val_accuracy: 0.1602 - val_loss: 3.5510\n",
      "Epoch 192/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1607 - loss: 3.5017 - val_accuracy: 0.1644 - val_loss: 3.5304\n",
      "Epoch 193/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1558 - loss: 3.5162 - val_accuracy: 0.1656 - val_loss: 3.5284\n",
      "Epoch 194/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1574 - loss: 3.5230 - val_accuracy: 0.1686 - val_loss: 3.5296\n",
      "Epoch 195/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1647 - loss: 3.4899 - val_accuracy: 0.1674 - val_loss: 3.5228\n",
      "Epoch 196/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1521 - loss: 3.5258 - val_accuracy: 0.1598 - val_loss: 3.5371\n",
      "Epoch 197/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1597 - loss: 3.5190 - val_accuracy: 0.1544 - val_loss: 3.5648\n",
      "Epoch 198/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1564 - loss: 3.5109 - val_accuracy: 0.1668 - val_loss: 3.5281\n",
      "Epoch 199/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1511 - loss: 3.5367 - val_accuracy: 0.1638 - val_loss: 3.5367\n",
      "Epoch 200/200\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1560 - loss: 3.5359 - val_accuracy: 0.1658 - val_loss: 3.5401\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1597 - loss: 3.5245\n",
      "Test Loss: 3.5183825492858887, Test Accuracy: 0.16278699040412903\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "softmax_model = Sequential()\n",
    "softmax_model.add(Dense(16, activation='relu', input_shape=(19,)))\n",
    "softmax_model.add(BatchNormalization())\n",
    "softmax_model.add(Dense(32, activation='relu'))\n",
    "softmax_model.add(Dropout(0.2))\n",
    "softmax_model.add(Dense(101, activation='softmax')) \n",
    "softmax_model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "softmax_model.summary()\n",
    "\n",
    "\n",
    "history = softmax_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "loss, accuracy = softmax_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 57/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Tolerance Accuracy (3): 31.23%\n",
      "Tolerance Accuracy (5): 39.57%\n"
     ]
    }
   ],
   "source": [
    "y_pred = softmax_model.predict(X_test)\n",
    "y_pred = y_pred / y_pred.sum(axis=1, keepdims=True)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "tolerance_3_accuracy = ((np.abs(y_pred_classes - y_test) <= 3).sum() / len(y_test)) * 100\n",
    "tolerance_5_accuracy = ((np.abs(y_pred_classes - y_test) <= 5).sum() / len(y_test)) * 100\n",
    "\n",
    "print(f\"Tolerance Accuracy (3): {tolerance_3_accuracy:.2f}%\")\n",
    "print(f\"Tolerance Accuracy (5): {tolerance_5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Model pipeline -------\n",
    "\n",
    "#EDA\n",
    "# -- Understanding the data\n",
    "#Data preprocessing\n",
    "# -- Data cleaning ( removing outliers )\n",
    "# -- Data imputation\n",
    "# -- Data Labelling\n",
    "# -- Data scaling\n",
    "#Feature engineering\n",
    "# -- Selecting Features\n",
    "#Modek Selection\n",
    "# -- Neural network or traditional simple model\n",
    "# -- Semantic model analysis with movie info\n",
    "# Model Evaluation\n",
    "# -- Test results evaluation(MAE)\n",
    "# -- Parametric evaluation with some tolerance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
